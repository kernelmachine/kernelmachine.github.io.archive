<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Introducing Utah &middot; Suchin
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  
  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-08">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Suchin
        </a>
      </h1>
      <p class="lead">சச்சின் | ساشين | sʌʧɪn</p>
      <p class="lead">Graduate student at the University of Washington studying NLP.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/publications/">Publications</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/talks/">Talks and Conferences</a>
          
        
      

      <a class="sidebar-nav-item" href="https://twitter.com/ssgrn">Twitter</a>
      <a class="sidebar-nav-item" href="https://github.com/kernelmachine">GitHub</a>
    </nav>

    <p>&copy; 2018. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Introducing Utah</h1>
  <span class="post-date">28 Dec 2016</span>
  <p>Recently, I’ve been working on a Rust crate for tabular data manipulation. I’m excited to share the current state of the project.</p>

<h2 id="a-dataframe-for-rust">A dataframe for Rust</h2>

<p>Languages like <a href="http://pandas.pydata.org/">Python</a>, <a href="http://www.r-tutor.com/r-introduction/data-frame">R</a>, and <a href="https://github.com/JuliaStats/DataFrames.jl">Julia</a> have popularized the  <em>dataframe</em>, which is an abstraction over a collection of <em>named</em> arrays. The dataframe allows users to access, transform, and compute over two-dimensional data that may have mixed types.</p>

<p><a href="https://github.com/kernelmachine/utah"><strong>Utah</strong></a> is a dataframe crate backed by <a href="https://github.com/bluss/rust-ndarray">ndarray</a> for type-conscious tabular data manipulation with an expressive, functional interface.</p>

<h2 id="overall-goals-of-project">Overall goals of project</h2>

<h4 id="functional-interface-to-transform-data">Functional interface to transform data</h4>

<p>Transformations are composable, repeatable, and readable.</p>

<h4 id="iterator-adapter-implementations-for-performance-and-laziness">Iterator adapter implementations for performance and laziness</h4>

<p>Data transformations are implemented with Rust’s iterators, which are fast, safe, and lazy.</p>

<h4 id="leverage-reference-locality-for-performance">Leverage reference locality for performance</h4>

<p>Most implementations of the dataframe involve some sort of map between column names and the underlying data. So during computations, you’re likely incurring performance hits while chasing pointers around in memory. In particular, row-wise operations can be much slower than column-wise ones.</p>

<p>I wanted to explore the effects of keeping data close together in memory. This crate is backed by ndarray to hold data, and enums to support mixed types. At the end of this post, I’ll describe an alternate implementation that sacrifices data locality to be able to have mixed types without wrappers.</p>

<h4 id="solid-error-handling">Solid error handling</h4>

<p>There are many errors that can occur while querying dataframes. For example, imagine selecting a column that doesn’t exist, or joining two dataframes that don’t have a common key. Such simple errors can be hidden in a sea of complex data transformations. The goal here is to provide compile-time error handling of these sorts of mistakes. I explore potential avenues to accomplish this goal at the end of this post.</p>

<h2 id="internals">Internals</h2>

<p><em>Note: The internals of the project are subject to alter in the future; I’ll try to keep an updated post describing changes.</em></p>

<h3 id="the-dataframe">The DataFrame</h3>

<p>There are two core types in Utah: the <strong>DataFrame</strong> and the <strong>DataFrameIterator</strong>.</p>

<p>Utah dataframes are defined as follows:</p>

<pre><code class="language-rust">pub struct DataFrame&lt;T&gt;
    where T: UtahNum,
          // ^ math ops like Add/Mul/etc, Empty, and others.
{
    pub columns: Vec&lt;String&gt;,
    pub data: Matrix&lt;T&gt;,
    pub index: Vec&lt;String&gt;,
}
</code></pre>

<p>The <code>DataFrame</code> takes the generic parameter <em>T</em>, which corresponds to the type of data in the inner matrix.</p>

<p>The <code>DataFrame</code> is read-only by default. To operate on a dataframe that is read-write, you can use a <code>DataFrameMut</code>:</p>

<pre><code>pub struct DataFrameMut&lt;'a, T&gt;
    where T: 'a + UtahNum
{
    pub columns: Vec&lt;String&gt;,
    pub data: MatrixMut&lt;'a, T&gt;,
    pub index: Vec&lt;String&gt;,
}
</code></pre>

<p>The only thing we’ve changed is the <code>data</code> field – from a <code>Matrix&lt;T&gt;</code> to a <code>MatrixMut&lt;T&gt;</code>. For simplicity, we’ll disregard the mutable dataframe for the rest of this post, but know that everything we talk about below extends to the mutable variant.</p>

<p>The inner data is of type <code>Matrix&lt;T&gt;</code>, an alias to a <a href="http://bluss.github.io/rust-ndarray/master/ndarray/type.Array2.html">2-D array</a> from the ndarray crate.</p>

<pre><code class="language-rust">pub type Matrix&lt;T&gt; = Array2&lt;T&gt;;
</code></pre>

<p>The data that the Matrix contains implement all the traits associated with the custom trait <em>UtahNum</em> (ie <code>Add</code>,<code>Sub</code>,<code>Mul</code>,<code>Div</code>, <code>One</code> and <code>Zero</code>) for computations, as well as the custom trait <em>Empty</em>.</p>

<p>Empty values are an unfortunate reality of most datasets, and manifest itself in different types depending on the context. For example, empty values may be <code>NAN</code> if you’re working with float data, an empty string with <code>String</code> data, or <code>0</code> with <code>Int</code> data. We use the <code>Empty</code> trait to define empty values for any type we want to use in a dataframe:</p>

<pre><code class="language-rust">pub trait Empty&lt;T&gt; {
    fn empty() -&gt; T;
    fn is_empty(&amp;self) -&gt; bool;
}
</code></pre>

<p>We ask, for type <code>T</code>, what should we consider as an empty value, and when is a value equal to empty? In the case of <code>f64</code>, we might implement the trait as follows:</p>

<pre><code class="language-rust">impl Empty&lt;f64&gt; for f64 {
    fn empty() -&gt; f64 {
        NAN
    }
    fn is_empty(&amp;self) -&gt; bool {
        self.is_nan()
    }
}
</code></pre>

<p>The columns/index are just names of the columns and rows of the dataframe, respectively.</p>

<h3 id="the-dataframeiterator">The DataFrameIterator</h3>

<p>The <code>DataFrameIterator</code> is what we use to perform transformations and computations. The <code>DataFrameIterator</code> is of the following type:</p>

<pre><code>pub struct DataFrameIterator&lt;'a, I, T: 'a&gt;
    where I: Iterator&lt;Item = Window&lt;'a, T&gt;&gt;
{
    pub names: Iter&lt;'a, String&gt;,
    pub data: I,
    pub other: Vec&lt;String&gt;,
    pub axis: UtahAxis,
}
</code></pre>

<p>First up, notice that we’ve now got lifetimes in the type. The DataFrameIterator is just a reference to a dataframe that owns the original data, and cannot outlive it. Ideally, you’ll have to read the data into memory only once.</p>

<p>Next, the trait bound on the dataframe iterator is <code>Iterator&lt;Item = Window&lt;'a, T&gt;&gt;</code>. <code>Window&lt;'a, T&gt;</code> is another type alias:</p>

<pre><code>pub type Window&lt;'a, T&gt; = (String, ArrayView1&lt;'a, T&gt;);
</code></pre>

<p>The <code>ArrayView1</code> <a href="`http://bluss.github.io/rust-ndarray/master/ndarray/type.ArrayView1.html`">type</a> is a column or row slice of the original data. The <code>Iterator</code> bound tells us that the <code>DataframeIterator</code> iterates over <em>views</em> of the data, along with their names (i.e. a column or index value).  The dataframe lives in a contiguous area of memory, and to iterate over it, we just slide a window over the stride of the vector that represents the matrix containing the data. The iterator is realized through ndarray’s <code>AxisIter</code><a href="&quot;http://bluss.github.io/rust-ndarray/master/ndarray/struct.AxisIter.html&quot;">type</a>.</p>

<p>Finally, the struct fields:</p>

<ul>
  <li>
    <p><code>data</code> just houses the iterator over the “windows” we just discussed.</p>
  </li>
  <li>
    <p><code>axis</code> tells the dataframe iterator which direction you want to iterate over. This field is of type <code>UtahAxis</code>, an enum over two different directions of iteration:</p>
  </li>
</ul>

<pre><code class="language-rust">pub enum UtahAxis {
    Row,
    Column,
}
</code></pre>

<ul>
  <li>
    <p><code>names</code> is an iterator over the axis label (index or columns) you’re iterating over.</p>
  </li>
  <li>
    <p><code>other</code> is the axis label that you’re <em>not</em> iterating over. We just hold onto this value in case you want to allocate the transformation into a new dataframe.</p>
  </li>
</ul>

<h2 id="creating-a-dataframe">Creating a dataframe</h2>

<p>There are multiple ways to create a dataframe. The most straightforward way is to use a <em>builder pattern</em>, which allows you to overwrite individual fields of the dataframe successively:</p>

<pre><code>
use utah::prelude::*;
let c = arr2(&amp;[[2., 6.], [3., 4.], [2., 1.]]);
let df: DataFrame&lt;f64&gt; = DataFrame::new(c)
                                  .columns(&amp;["a", "b"])?
                                  .index(&amp;["1", "2", "3"])?;
</code></pre>

<p>The <code>?</code> operator, newly introduced syntax for accessing the <code>Result</code> type, is there to prevent you from adding columns or indices that don’t match the dimensions of the underlying data.</p>

<p>There’s also <code>dataframe!</code> and <code>col!</code> macros which you can use to create new dataframes on the fly:</p>

<pre><code>let k: DataFrame&lt;f64&gt; = dataframe!(
    {
        "a" =&gt;  col!([2., 3., 2.]),
        "b" =&gt;  col!([2., NAN, 2.])
    });
</code></pre>

<p>Finally, you can import data from a CSV.</p>

<pre><code>let file_name = "test.csv";                            
let df: Result&lt;DataFrame&lt;InnerType&gt;&gt; = DataFrame::read_csv(file_name);
</code></pre>

<p>Note that Utah’s <code>ReadCSV</code> trait is pretty barebones right now.</p>

<h3 id="combinators">Combinators</h3>

<p>The user interacts with Utah dataframes by chaining combinators, which are adapters over the dataframe iterator. Each operation is lazy by default. You can chain as many combinators as you want, but it won’t do anything until you invoke a collection operation like <code>as_df</code>, which would allocate the results into a new dataframe, or <code>as_matrix</code>, which would allocate the results into a 2-D ndarray.</p>

<p>I’ve organized the combinators that I’ve built so far into four different types, but there are naturally many more. The nice thing is that the iterator adapter design makes it extremely easy to add new combinators to the project.</p>

<h4 id="transform-combinators">Transform combinators</h4>

<p>These combinators are meant for changing the shape of the data you’re working with. Combinators in this class include <code>select</code>, <code>remove</code>, and <code>append</code>.</p>

<pre><code>let a = arr2(&amp;[[2.0, 7.0], [3.0, 4.0], [2.0, 8.0]]);
let df = DataFrame::new(a).index(&amp;["a", "b", "c"]).unwrap();
let res = df.select(&amp;["a", "c"], UtahAxis::Row);
</code></pre>

<h4 id="process-combinators">Process combinators</h4>

<p>Process combinators are meant for changing the original data you’re working with. Combinators in this class include <code>impute</code> and <code>mapdf</code>. Impute replaces missing values of a dataframe with the mean of the corresponding axis. Note that these operations require the use of a <code>DataFrameMut</code>.</p>

<pre><code>let mut a: DataFrameMut&lt;f64&gt; = dataframe!(
    {
        "a" =&gt;  col!([NAN, 3., 2.]),
        "b" =&gt;  col!([2., NAN, 2.])
    });
let res = df.impute(ImputeStrategy::Mean, UtahAxis::Column);
</code></pre>

<h4 id="interact-combinators">Interact combinators</h4>

<p>Interact combinators are meant for interactions between dataframes. They generally take at least two dataframe arguments. Combinators in this class include <code>inner_left_join</code>, <code>outer_left_join</code>, <code>inner_right_join</code>, <code>outer_right_join</code>, and <code>concat</code>.</p>

<pre><code>let a: DataFrame&lt;f64&gt; = dataframe!(
    {
        "a" =&gt;  column!([NAN, 3., 2.]),
        "b" =&gt;  column!([2., NAN, 2.])
    });
let b: DataFrame&lt;f64&gt; = dataframe!(
    {
        "b" =&gt;  column!([NAN, 3., 2.]),
        "c" =&gt;  column!([2., NAN, 2.])
    });
let res = a.inner_left_join(&amp;b).as_df()?;
</code></pre>

<h4 id="aggregate-combinators">Aggregate combinators</h4>

<p>Aggregate combinators are meant to reduce a chain of combinators to some result. These combinators are usually the last operation in a chain, but don’t necessarily have to be. Combinators in this class include <code>sumdf</code>, <code>mindf</code>, <code>maxdf</code>, <code>stdev</code> (standard deviation), and <code>mean</code>. Currently, aggregate combinators are not iterator collection operations, because they do not invoke a chain. This may change in the future.</p>

<pre><code>let a = arr2(&amp;[[2.0, 7.0], [3.0, 4.0], [2.0, 8.0]]);
let df = DataFrame::new(a).index(&amp;[1, 2, 3])?.columns(&amp;["a", "b"])?;
let res = df.mean(UtahAxis::Row);
</code></pre>

<h4 id="chaining-combinators">Chaining combinators</h4>

<p>The real power of combinators comes from the ability to chain them together in expressive transformations that are easy to parse. You can do things like this:</p>

<pre><code>let result = df.df_iter(UtahAxis::Row)
               .remove(&amp;["1"])
               .select(&amp;["2"])
               .append("8", new_data.view())
               .inner_left_join(df_1)
               .sumdf()
               .as_df()?
</code></pre>

<p>Because we’ve built the chain on a row-wise dataframe iterator, each subsequent operation will only operate on the rows of the dataframe.</p>

<h2 id="creating-new-combinators">Creating new combinators</h2>

<p>Rust’s trait system allows for repeatable patterns throughout the project, especially when it comes to designing combinators. By following these steps, you can easily add your own combinators for new transformations or computations.</p>

<h5 id="define-a-new-struct-combinator-with-necessary-data">1. Define a new struct <code>Combinator</code>, with necessary data.</h5>

<p>The combinator should contain an iterator over items of type <code>Window&lt;'a, T&gt;</code> – a matrix slice and its name.  <code>Sum</code> contains the Iterator, the axis label it’s not iterating over, and the axis of iteration.</p>

<pre><code>    pub struct Sum&lt;'a, I: 'a, T: 'a, S&gt;
      where I: Iterator&lt;Item = Window&lt;'a, T&gt;&gt; + 'a,
            T: UtahNum,
            S: Identifier
  {
      data: I,
      other: Vec&lt;String&gt;,
      axis: UtahAxis,
  }
</code></pre>

<h5 id="impl-iterator-for-combinator">2. impl Iterator for Combinator</h5>

<p>What’s the output of this combinator during iteration over the dataframe? In the case of <code>Sum</code>, we’re just taking the scalar sum of elements in a “window”.</p>

<pre><code>      impl&lt;'a, I, T&gt; Iterator for Sum&lt;'a, I, T&gt;
        where I: Iterator&lt;Item = Window&lt;'a, T&gt;&gt;,
              T: UtahNum    
    {
        type Item = T;
        fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
            match self.data.next() {
                None =&gt; return None,
                Some((_, dat)) =&gt; return Some(dat.scalar_sum()),
            }
        }
    }
</code></pre>

<h5 id="add-impl-combinator-with-a-fn-new">3. Add <code>impl Combinator</code> with a <code>fn new()</code>.</h5>

<p>How do you create this combinator from scratch? That’s easy:</p>

<pre><code>      impl&lt;'a, I, T&gt; Sum&lt;'a, I, T&gt;
        where I: Iterator&lt;Item = Window&lt;'a, T&gt;&gt;,
              T: UtahNum
    {
        pub fn new(df: I, other: Vec&lt;String&gt;, axis: UtahAxis) -&gt; Sum&lt;'a, I, T&gt; {
            Sum {
                data: df,
                other: other,
                axis: axis,
            }
        }
    }
</code></pre>

<h5 id="add-fn-combinatorself--iterator-to-its-categorical-trait">4. Add <code>fn combinator(self : Iterator)</code> to its categorical trait</h5>

<p>The function you add should invoke the <code>new</code> constructor defined in the third step. In the case of <code>Sum</code>, we’ll add it to the <code>Aggregate</code> trait. Define a new categorical trait if the new combinator doesn’t fit with the built-in ones.</p>

<pre><code>pub trait Aggregate&lt;'a, T&gt;
    where T: UtahNum
  {
    fn sumdf(self) -&gt; Sum&lt;'a, Self, T&gt;
        where Self: Sized + Iterator&lt;Item = Window&lt;'a, T&gt;&gt;;
  }
</code></pre>

<h5 id="add-fn-combinatorself--dataframe-to-the-operations-trait">5. Add <code>fn combinator(self : DataFrame)</code> to the <code>Operations</code> trait</h5>

<p>The function you add should invoke the combinator from an allocated dataframe.</p>

<pre><code>  pub trait Operations&lt;'a, T&gt;
    where T: 'a + UtahNum
  {
    fn sumdf(&amp;'a mut self, axis: UtahAxis) -&gt; SumIter&lt;'a, T&gt;;
  }
</code></pre>

<p><code>SumIter</code> is another alias:</p>

<pre><code>pub type SumIter&lt;'a, T&gt; = Sum&lt;'a, DataFrameIterator&lt;'a, T&gt;, T&gt;;
</code></pre>

<h5 id="impl-asdataframe-for-combinator">6. impl AsDataFrame for Combinator</h5>

<p>The function you add will let you go from the <code>Combinator</code> iterator to an allocated dataframe/matrix/array. Read next section for more details on this trait.</p>

<pre><code>  pub trait ToDataFrame&lt;'a, I, T&gt;
    where T: UtahNum + 'a
  {
          fn as_df(self) -&gt; Result&lt;DataFrame&lt;T&gt;&gt; where Self: Sized + Iterator&lt;Item = I&gt;;
  }
</code></pre>

<p>It’s interesting to think about how to reduce combinators to iterators adapters that we’re familiar with. For example, the <code>concat</code> combinator is just a <code>Chain</code>. More complicated combinators like <code>Groupby</code> can be thought of as a <code>Map</code> on a <code>Filter</code>. These conceptual relationships can help you think about how to best implement a new combinator.</p>

<h3 id="collection">Collection</h3>

<p>There are many ways you can access or store the result of your chained operations. Because each data transformation is just an iterator, we can naturally collect the output of chained operations via <code>collect()</code> or a <code>for</code> loop:</p>

<pre><code>for x in df.concat(&amp;df_1) {
   println!("{:?}", x)
}
</code></pre>

<p>But we also have an <code>ToDataFrame</code> trait, which dumps the output of chained combinators into a new dataframe, matrix, or array, so we can do something like the following:</p>

<pre><code>let maximum_values = df.concat(&amp;df_1).maxdf(UtahAxis::Column).as_df()?;
</code></pre>

<h3 id="the-innertype">The InnerType</h3>

<p>Now, I mentioned in the beginning that most dataframes provide mixed types, and I wanted to provide a similar functionality here. In the module <code>utah::mixedtypes</code>, I’ve defined <code>InnerType</code>, which is an enum over various types of data that can co-exist in the same dataframe:</p>

<pre><code>pub enum InnerType {
    Float(f64),
    Int64(i64),
    Int32(i32),
    Str(String),
    Empty,
}
</code></pre>

<p>With this wrapper, you can have <code>String</code> and <code>f64</code> in the same dataframe.</p>

<p>In general, this may not be the best approach to supporting mixed types in this project, because there are performance hits for computation when working with type wrappers. I discuss alternative avenues to achieving this goal below.</p>

<p>An important consequence of supporting mixed types is that because strings are not <code>Copy</code>, the dataframe is not <code>Copy</code>. This means that you may run into unexpected ownership problems while building data transformations. There are some API ergonomics to be ironed out.</p>

<h2 id="next-steps">Next steps</h2>

<p>Next, I’ll catalog some of the thoughts on future directions for this project.</p>

<h4 id="comparing-a-map-implementation-to-a-reference-local-one">Comparing a map implementation to a reference-local one</h4>

<p>There are some drawbacks to the iterator adapter design which may warrant re-visiting the map implementation I mentioned in the beginning of the post. For example, <code>select</code> is currently <code>O(n)</code> when it could be <code>O(1)</code>.</p>

<p>Furthermore, we have to wrap our data with an enum (ie <code>InnerType</code>) to be able to support mixed types in the same array. Computations are not as fast as they could be.</p>

<p>Ideally, we could work with raw types directly. An alternate dataframe implementation sacrifices reference locality for the ability to work with raw types in the mixed-context.</p>

<pre><code class="language-rust">pub struct MixedDataFrame&lt;T&gt;
    where T: UtahNum
{
    pub data: HashMap&lt;String, Array1&lt;T&gt;&gt;,
    pub index: HashMap&lt;String, usize&gt;,
}
</code></pre>

<p>This dataframe’s design implies that we will need two separate types for row-wise and column-wise iteration.</p>

<p>Row-wise iteration would could be a multi-zip operation where we connect each value of the same index across all columns.</p>

<pre><code>pub struct MixedDataFrameRowIterator&lt;'a, T: 'a&gt;
    where T: UtahNum
          Zip&lt;AxisIter&lt;'a, T, usize&gt;&gt;: Iterator
{
    pub names: Iter&lt;'a, String&gt;,
    pub data: Zip&lt;AxisIter&lt;'a, T, usize&gt;&gt;,
    pub other: Vec&lt;String&gt;,
    pub axis: UtahAxis,
}
</code></pre>

<p>On the other hand, column-wise iteration could be an iterator over the HashMap.</p>

<pre><code>pub struct MixedDataFrameColIterator&lt;'a, T: 'a&gt;
    where T: UtahNum
          Iter&lt;'a, String, Array1&lt;T&gt;&gt;: Iterator
{
    pub data: Iter&lt;'a, String, Array1&lt;T&gt;&gt;,
    pub other: Vec&lt;String&gt;,
    pub axis: UtahAxis,
}
</code></pre>

<p>Further explorations into the map implementation are needed to see if it realizes performance benefits over the reference-local one.</p>

<h4 id="better-error-handling-with-compile-time-dimension-checking">Better Error handling with compile time dimension checking</h4>

<p>How do we effectively prevent user errors during data transformation <em>at compile time</em>?</p>

<p>So far, the only error handling is in the <code>new()</code> function, where we check whether the dimensions of the axis labels match that of the underlying data. This actually handles a ton of common errors, like selecting or removing a column that doesn’t exist. But while it does panic in the right situations, the errors are not that useful in figuring out what the actual mistake was:</p>

<pre><code>IndexShapeMismatch(exp: String , act: String) {
  display("index shape mismatch. Expected length: {}, Actual length: {}",  exp, act)
}

ColumnShapeMismatch(exp: String , act: String) {
  display("column shape mismatch. Expected length: {}, Actual length: {}",  exp, act)
}

</code></pre>

<p>Furthermore, the errors are only caught at runtime.</p>

<p>One thing I’ve been thinking about is compile-time dimension checking with the <a href="https://github.com/paholg/typenum">typenum</a> and <a href="https://github.com/fizyk20/generic-array">genericarray</a> crates, which provide compile-time numeric operations and array dimensions, respectively.</p>

<p>Using these crates, the dimensions of the inner data and axis labels could be embedded in trait bounds:</p>

<pre><code>pub struct DataFrame&lt;T, N, M, O, P&gt;
    where T: UtahNum
          M: ArrayLength&lt;String&gt; + Same&lt;P&gt;,
          P: ArrayLength&lt;T&gt; + Same&lt;M&gt;,
          N: ArrayLength&lt;String&gt; + Same&lt;O&gt;,
          O: ArrayLength&lt;T&gt; + Same&lt;N&gt;,
{
    pub columns: GenericArray&lt;String, M&gt;,
    pub data: GenericArray&lt;GenericArray&lt;T,O&gt;, P&gt;,
    pub index: GenericArray&lt;String, N&gt;,
    phantom_0: PhantomData&lt;&lt;N as Same&lt;O&gt;&gt;::Output&gt;,
    phantom_1: PhantomData&lt;&lt;M as Same&lt;P&gt;&gt;::Output&gt;,
}
</code></pre>

<p>The trait bounds imply that a combinator chain will not compile if the length of the index <code>M</code> and columns <code>N</code> don’t match the dimensions of the underlying data.</p>

<h4 id="streaming-dataframes">Streaming DataFrames</h4>

<p>In reality, the current implementation is an imperfect workaround of what I <em>really</em> want the dataframe and its combinators to be. Right now, the data owner (<code>DataFrame</code>) is separated from the iterator (<code>DataFrameIterator</code>) and the combinators.</p>

<p>I would like the dataframe to be an iterator over some data held in disk, and each combinator borrowed values from a buffer maintained by the dataframe.  Then the real power of the iterator adapter design is realized: we can work with datasets that may not fit into memory.</p>

<p>What I’m essentially talking about are <em>streaming iterators</em>, which has been discussed at length <a href="https://users.rust-lang.org/t/returning-borrowed-values-from-an-iterator/1096">here</a> and <a href="https://github.com/emk/rust-streaming">here</a>. There’s another <a href="https://github.com/sfackler/streaming-iterator">interesting crate</a> around this effort too. It’s an exciting concept.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’ve introduced a new Rust crate for handling complex data transformations with two dimensional iterator adapters. This crate, while extremely nascent, has shown a few strengths so far:</p>

<ol>
  <li>Functional chaining of combinators makes code easy to understand.</li>
  <li>Iterator adapter design makes the code extremely repeatable and easy to extend to new domains.</li>
  <li>We get all the benefits of working with Rust’s iterators, which are fast, safe, and lazy.</li>
  <li>There’s a lot of interesting future work on better mixed type support, compile time numbers, and streaming.</li>
</ol>

<p>That’s all from me – happy holidays!</p>

</div>

    </div>

  </body>
</html>
