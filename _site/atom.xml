<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>suchin</title>
 <link href="https://suchin.co/atom.xml" rel="self"/>
 <link href="https://suchin.co/"/>
 <updated>2017-03-21T09:06:59-07:00</updated>
 <id>https://suchin.co</id>
 <author>
   <name>Suchin Gururangan</name>
   <email></email>
 </author>

 
 <entry>
   <title>Autodifferentiation and Backpropagation</title>
   <link href="https://suchin.co/2017/03/18/Autodifferentiation-and-Backpropagation/"/>
   <updated>2017-03-18T00:00:00-07:00</updated>
   <id>https://suchin.co/2017/03/18/Autodifferentiation-and-Backpropagation</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Much of this blog post was inspired by &lt;a href=&quot;http://cs231n.github.io&quot;&gt;CS231n&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1502.05767&quot;&gt;this&lt;/a&gt; paper. Highly recommended reads.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The derivative is an important operation in machine learning, primarily for parameter optimization with loss functions. However, computing analytic derivatives in the finite context of 32 or 64 bits has required significant work. This post will detail the various approaches that we can take to compute the derivative of arbitrary functions. First, we’ll discuss numerical differentiation, which, while simple and intuitive, suffers from floating point errors. Then, we’ll discuss symbolic differentiation, which suffers from complexity problems. Finally, we’ll discuss auto-differentiation, the most popular method to compute derivatives with both exactness and simplicity. We’ll also discuss &lt;em&gt;backpropagation&lt;/em&gt;, an analogue of auto-differentiation that is the primary method of learning in neural networks.&lt;/p&gt;

&lt;h2 id=&quot;numerical-differentiation&quot;&gt;Numerical differentiation&lt;/h2&gt;

&lt;p&gt;Numerical differentation is rooted in the &lt;em&gt;finite differences approximation&lt;/em&gt; definition of the derivative. Formally, for a function &lt;script type=&quot;math/tex&quot;&gt;f : \mathbb{R}^N \rightarrow \mathbb{R}&lt;/script&gt;, we can compute the gradient &lt;script type=&quot;math/tex&quot;&gt;\triangledown f = (\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2},...,\frac{\partial f}{\partial x_n})&lt;/script&gt; as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial f}{\partial x_i} \approx \lim_{h \rightarrow 0} \frac{f(x_i + h) - f(x_i)}{h}&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;h &gt; 0&lt;/script&gt; is some small step size. Essentially, given some tangent line between &lt;script type=&quot;math/tex&quot;&gt;f(x_i)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;f(x_i + h)&lt;/script&gt;, we estimate its slope by calculating the slope of &lt;em&gt;secant line&lt;/em&gt;  between &lt;script type=&quot;math/tex&quot;&gt;(x, f(x))&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;(x_i + h , f(x_i + h))&lt;/script&gt;, and say that as &lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; approaches 0, the derivative of the secant line approaches the derivative of the tangent line. Here’s a graphic of that process:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pegasos1.github.io/public/20170318/num_diff.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The issue with numerical differentiation is that it is inherently ill-conditioned and unstable. It cannot be exactly fitted to a finite representation without rounding or truncation, thus introducing approximation errors in the computation. The size of &lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; directly correlates with the amount of instability in the differentiation. If &lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; is too small, then the subtraction from &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; will yield a larger rounding error. On the other hand, if &lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; is too large, the estimate of the slope of the tangent could be worse. Most people advise against using the finite differences approximation of the derivative in machine learning systems.&lt;/p&gt;

&lt;h2 id=&quot;symbolic-differentiation&quot;&gt;Symbolic differentiation&lt;/h2&gt;

&lt;p&gt;One insight is that if we were somehow able to algebraically map functions to their derivatives, then we could likely achieve near full precision on our derivatives. For example, it is well known that the derivative of &lt;script type=&quot;math/tex&quot;&gt;f(x) = x^2&lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt;2x&lt;/script&gt;. Computing &lt;script type=&quot;math/tex&quot;&gt;2x&lt;/script&gt; is trivial, compared to using the finite differences approximation, with all its computational problems.&lt;/p&gt;

&lt;p&gt;This is one of the primary motives of &lt;em&gt;symbolic differentiation&lt;/em&gt;, the automatic algebraic manipulation of expressions based on well known rules of differentation such as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial x}(f(x) + g(x)) = \frac{\partial f}{\partial x} + \frac{\partial g}{\partial x}&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial x}(\frac{f(x)}{g(x)}) = \frac{g(x)\frac{\partial f}{\partial x} - f(x)\frac{\partial g}{\partial x}}{g(x)^2}&lt;/script&gt;

&lt;p&gt;Symbolic differentiation is a representational problem, and can quickly become extremely complex, depending on the function to be manipulated. But once the representation is achieved, derivatives can be computed much more accurately than with finite differences approximation. I won’t be going into more detail on symbolic differentiation’s internals, mainly because it’s complex, but I’ll point you &lt;a href=&quot;http://homepage.divms.uiowa.edu/~stroyan/CTLC3rdEd/3rdCTLCText/Chapters/ch6.pdf&quot;&gt;here&lt;/a&gt; if you want more details.&lt;/p&gt;

&lt;h2 id=&quot;forward-autodifferentiation&quot;&gt;Forward Autodifferentiation&lt;/h2&gt;

&lt;p&gt;Autodifferentiation (AD) is a method that is both exact and simple. The basic motivation for AD is that &lt;em&gt;any arbitrary function can be represented as a composition of simpler ones&lt;/em&gt;. Under functional composition, one can compute the derivative of a function using the &lt;em&gt;chain rule&lt;/em&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = g(h(x)) \implies f&#39;(x) = g&#39;(h(x)) h&#39;(x)&lt;/script&gt;

&lt;p&gt;Because &lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; are assumed to be simpler components of the arbitrary function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;, their derivatives are also simpler to compute.&lt;/p&gt;

&lt;p&gt;An example would help explain this idea.&lt;/p&gt;

&lt;p&gt;Let&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = \frac{ln(x)(x+3) + x^2} {sin(x)}&lt;/script&gt;

&lt;p&gt;We could take the derivative of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; using the rules we learned in high school. But there is an easier way. Fortunately, &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is a composition of very simple functions:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp; v_0 = ln(x) \\
&amp; v_1 = x + 3 \\
&amp; v_2 = v_0v_1 \\
&amp; v_3 = x^2 \\
&amp; v_4 = v_2 + v_3 \\
&amp; v_5 = sin(x)\\
&amp; v_6 = \frac{v_4}{v_5}\\
&amp; f = v_6
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;\dot v_i = \frac{\partial v_i}{\partial x}&lt;/script&gt;. Differentiation proceeds via a forward pass:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp; \dot v_0 = \frac{1}{x} \\
&amp; \dot v_1 = 1\\
&amp; \dot v_2 = v_0 \dot v_1 + \dot v_0 v_1 = ln(x) + \frac{1}{x}\\
&amp; \dot v_3 = 2x \\
&amp; \dot v_4 = \dot v_2 + \dot v_3 = ln(x) + \frac{1}{x} + 2x\\
&amp; \dot v_5 = cos(x)\\
&amp; \dot v_6 = \frac{v_5 \dot v_4 - v_4 \dot v_5 }{v_5^2}\\
&amp; \dot f = \dot v_6 = \frac{sin(x)(ln(x) + \frac{1}{x} + 2x) - (ln(x)(x+3) + x^2)cos(x)}{sin^2(x)}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;The important things to notice are that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The forward computation of &lt;script type=&quot;math/tex&quot;&gt;\dot f&lt;/script&gt; involves the &lt;strong&gt;staged computation&lt;/strong&gt; of very simple components of the function. These stages are trivial to compute.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is a linear flow through the derivative computation, mostly involving mere substitutions, which lends itself well to imperative programming.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We compute the derivative &lt;em&gt;exactly&lt;/em&gt;, and do not approximate any value.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, let’s look at the multi-dimensional case. Let &lt;script type=&quot;math/tex&quot;&gt;f : \mathbb{R}^N \rightarrow \mathbb{R}^M&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The derivative of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is expressed by the Jacobian matrix&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
J_f =

\begin{bmatrix}
\partial f_1 \over \partial x_1 &amp; ... &amp; \partial f_1 \over x_m \\
\vdots  &amp; \ddots &amp; \vdots \\
\partial f_n \over \partial x_1 &amp;  ... &amp; \partial f_n \over \partial x_m \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;J_f&lt;/script&gt; can be computed in just &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; forward AD passes across each dimension of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;When &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
N &lt;&lt; M %]]&gt;&lt;/script&gt;, then the forward pass is extremely efficient in computing the Jacobian.&lt;/p&gt;

&lt;p&gt;However, when &lt;script type=&quot;math/tex&quot;&gt;N &gt;&gt; M&lt;/script&gt;, another version of AD, called &lt;em&gt;reverse AD&lt;/em&gt;, is more efficent to compute derivatives of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; with respect to each input dimension. We’ll dig into that next.&lt;/p&gt;

&lt;h2 id=&quot;reverse-autodifferentiation&quot;&gt;Reverse Autodifferentiation&lt;/h2&gt;

&lt;p&gt;As opposed to forward autodifferentiation, which involves staged computations from the input to the output, reverse autodifferentiation evolves backwards from the function output.&lt;/p&gt;

&lt;p&gt;We propagate the derivative of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; with the &lt;em&gt;adjoint&lt;/em&gt; operator&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar v_i = \frac{\partial f}{\partial v_i}&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt; is some intermediate stage in the overall function computation. These derivatives measure the sensitivity of the output of the forward pass with respect to a particular stage.&lt;/p&gt;

&lt;p&gt;Reverse AD proceeds in two phases, one of a forward pass computation, and then reverse accumulation. The forward pass, like we outlined in the previous section, helps us keep track of the computational stages that make up the arbitrary function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;.  We then compute derivatives backwards until we arrive at the original input: &lt;script type=&quot;math/tex&quot;&gt;\bar x = \frac{\partial f}{\partial x}&lt;/script&gt;. Reverse AD is the preferred procedure when the function &lt;script type=&quot;math/tex&quot;&gt;f : \mathbb{R}^N \rightarrow \mathbb{R}^M&lt;/script&gt; has &lt;script type=&quot;math/tex&quot;&gt;N &gt;&gt; M&lt;/script&gt; because in reverse AD we only have to make &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; passes to compute the multi-dimensional gradient.&lt;/p&gt;

&lt;p&gt;For example, if&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\triangledown f = (\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2},...,\frac{\partial f}{\partial x_n})&lt;/script&gt;

&lt;p&gt;Then we only have to do 1 pass of reverse AD to compute &lt;script type=&quot;math/tex&quot;&gt;\triangledown f&lt;/script&gt;, while we have to do &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; passes of forward AD to get the same answer.&lt;/p&gt;

&lt;p&gt;Let’s go through an example of doing reverse AD to make the procedure clearer.&lt;/p&gt;

&lt;p&gt;Let&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_1, x_2) = \frac{ln(x_1) + x_2^2} {sin(x_1)x_2}&lt;/script&gt;

&lt;p&gt;First we do a forward pass on &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp; v_0 = x_1\\
&amp; v_1 = x_2\\
&amp; v_2 = ln(v_0) \\
&amp; v_3 = v_1^2 \\
&amp; v_4 = v_2 + v_3 \\
&amp; v_5 = sin(v_0)v_1\\
&amp; v_6 = \frac{v_4}{v_5}\\
&amp; f = v_6
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Then we begin at the output &lt;script type=&quot;math/tex&quot;&gt;f = v_6&lt;/script&gt; and propagate its derivative backwards using the chain rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp; \bar v_6 = \bar f\\
&amp; \bar v_5 = \bar v_6 \frac{\partial v_6}{\partial v_5} = \bar v_6 \frac{-v_4}{v_5^2}\\
&amp; \bar v_4 = \bar v_6 \frac{\partial v_6}{\partial v_4} = \bar v_6 \frac{1}{v_5}  \\
&amp; \bar v_3 = \bar v_4 \frac{\partial v_4}{\partial v_3} = \bar v_4 \textbf{1} \\
&amp; \bar v_2 = \bar v_4 \frac{\partial v_4}{\partial v_2} = \bar v_4 \textbf{1}\\
&amp; \bar v_1 = \bar v_3 \frac{\partial v_3}{\partial v_1} = \bar v_3 2v_1\\
&amp; \bar v_0 = \bar v_2 \frac{\partial v_2}{\partial v_0} = \bar v_2 \frac{1}{v_0}\\
&amp; \bar x_2 = \bar v_1\\
&amp; \bar x_1 = \bar v_0\\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;To compute &lt;script type=&quot;math/tex&quot;&gt;\bar x_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\bar x_2&lt;/script&gt;, we must recognize that &lt;script type=&quot;math/tex&quot;&gt;x_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;x_2&lt;/script&gt; affect the output &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; in distinct ways.&lt;/p&gt;

&lt;p&gt;In fact, it is helpful to view the forward pass as a computation graph, to visualize this point:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pegasos1.github.io/public/20170318/graph.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;x_1&lt;/script&gt; only affects &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; through &lt;script type=&quot;math/tex&quot;&gt;v_2&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;v_5&lt;/script&gt;, which means that through the multi-dimensional chain rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial f}{\partial x_1} = \frac{\partial f}{\partial v_0} = \frac{\partial f}{\partial v_2}\frac{\partial v_2}{\partial v_0} + \frac{\partial f}{\partial v_5}\frac{\partial v_5 }{\partial v_0}&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar v_0 = \bar v_2 \frac{\partial v_2}{\partial v_0} +  \bar v_5 \frac{\partial v_5 }{\partial v_0}&lt;/script&gt;

&lt;p&gt;On the other hand, &lt;script type=&quot;math/tex&quot;&gt;x_2&lt;/script&gt; only affects &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; through &lt;script type=&quot;math/tex&quot;&gt;v_3&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;v_5&lt;/script&gt;, so:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial f}{\partial x_2} = \frac{\partial f}{\partial v_1} = \frac{\partial f}{\partial v_3}\frac{\partial v_3}{\partial v_1} + \frac{\partial f}{\partial v_5}\frac{\partial v_5 }{\partial v_1}&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar v_1 = \bar v_3 \frac{\partial v_3}{\partial v_1} +  \bar v_5 \frac{\partial v_5 }{\partial v_1}&lt;/script&gt;

&lt;p&gt;Thus we show that with reverse AD, we can compute &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial f}{\partial x_1}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial f}{\partial x_2}&lt;/script&gt; with very elementary operations. As an exercise, set &lt;script type=&quot;math/tex&quot;&gt;\bar v_6 = 1&lt;/script&gt; and compute the gradient of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;By keeping track of stages in the forward pass of the reverse AD, the bottleneck of computing &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial f}{\partial x_1}&lt;/script&gt; and  &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial f}{\partial x_2}&lt;/script&gt; is reduced to computing &lt;script type=&quot;math/tex&quot;&gt;\bar v_6&lt;/script&gt;, which is only dependent on the complexity of the final stage of computation in &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Reverse autodifferentation is known as &lt;em&gt;backpropagation&lt;/em&gt; in deep learning, and forms the basic way that we update parameters of a neural network during learning. In the next section, we’ll dive into how to apply reverse autodifferentation to train neural networks.&lt;/p&gt;

&lt;h2 id=&quot;backpropagation-in-deep-learning&quot;&gt;Backpropagation in Deep Learning&lt;/h2&gt;

&lt;p&gt;Consider a two layer neural network. Given an input matrix &lt;script type=&quot;math/tex&quot;&gt;X \in R^{N x M}&lt;/script&gt; and output labels &lt;script type=&quot;math/tex&quot;&gt;y \in R^N&lt;/script&gt;, let &lt;script type=&quot;math/tex&quot;&gt;W_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;W_2&lt;/script&gt; be weight matrices corresponding to layer 1 and 2 respectively, and &lt;script type=&quot;math/tex&quot;&gt;b_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b_2&lt;/script&gt; be bias vectors corresponding to each weight matrix. Between layer 1 and 2 imagine we have an ReLU activation function &lt;script type=&quot;math/tex&quot;&gt;f(x) = max(0, x)&lt;/script&gt;, and imagine that we apply a softmax classifier after layer 2 to squash its output between &lt;script type=&quot;math/tex&quot;&gt;[0, 1]&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Here’s a rough diagram of the network we’ll be working with.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pegasos1.github.io/public/20170318/nnet.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;During learning, we want to provide input to the neural network, and then update the weights at each layer depending on the error computed by the loss function at the output. We’ll use reverse AD (or &lt;em&gt;backpropagation&lt;/em&gt;) to find the gradients of the loss function with respect to each weight matrix. Note that all the layers can be updated by merely knowing the derivative of the &lt;em&gt;last stage of computation&lt;/em&gt;, because as we saw in the last section, all previous stages’ derivatives can then be computed. This means that we’ll have to figure out what the derivative of our the softmax loss function is, and then we’re golden.&lt;/p&gt;

&lt;p&gt;We can model the neural network as a forward pass of staged computations from the input &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; to the softmax loss function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp; Y_1 = W_1X + b_1 \\
&amp; A_1 = max(0, Y_1) \\
&amp; Y_2 = W_2A_1 + b_2 \\
&amp; L = SoftmaxLoss(Y_2)\\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Here’s what the forward pass (prior to the loss function) would look like in Python, computing the class scores for the input.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt;  &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Y1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# first layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#  ReLU activation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# second layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# softmax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;How do we define the &lt;script type=&quot;math/tex&quot;&gt;SoftmaxLoss&lt;/script&gt; function in the output?&lt;/p&gt;

&lt;p&gt;Well, the softmax function applied to a score vector &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_k = \frac{e^{f_k}}{\sum_j e^{f_j}}&lt;/script&gt;

&lt;p&gt;The data loss function for a softmax classifier is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_i = -log(p_{y_i})&lt;/script&gt;

&lt;p&gt;Where &lt;script type=&quot;math/tex&quot;&gt;y_i&lt;/script&gt; is the index of the correct label.&lt;/p&gt;

&lt;p&gt;The softmax classifier loss for this network is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \underbrace{\frac{1}{N}\sum_i L_i}_\text{data loss} + \underbrace{\lambda [\sum_i\sum_j W_1^2 + \sum_i\sum_j W_2^2]}_\text{regularization loss}&lt;/script&gt;

&lt;p&gt;Rounding out the code for the forward pass, here’s what the loss function looks like in Python:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt;  &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_loss&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;During learning, we use gradient descent to optimize the network’s weight matrices &lt;script type=&quot;math/tex&quot;&gt;W_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;W_2&lt;/script&gt;. We update the weights with their gradients on &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; , &lt;script type=&quot;math/tex&quot;&gt;\partial L \over \partial W_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\partial L \over \partial W_2&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;To find &lt;script type=&quot;math/tex&quot;&gt;\partial L \over \partial W_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\partial L \over \partial W_2&lt;/script&gt;, we do the reverse accumulation phase of backpropagation.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp; \bar Y_2 = \bar L \frac {\partial L}{\partial Y_2}\\
&amp; \bar W_2 = \bar Y_2 \frac{\partial Y_2}{\partial W_2} = \bar Y_2 A_1 \\
&amp; \bar b_2 = \bar Y_2 \frac{\partial Y_2}{\partial b_2} = \bar Y_2 \textbf{1} \\
&amp; \bar A_1 = \bar Y_2 \frac{\partial Y_2}{\partial A_1} = \bar Y_2 W_2 \\
&amp; \bar Y_1 = \bar A_1 \frac{\partial A_1}{\partial Y_1} \\
&amp; \bar W_1 = \bar Y_1 \frac{\partial Y_1}{\partial W_1} = \bar Y_1 X \\
&amp; \bar b_1 = \bar Y_1 \frac{\partial Y_1}{\partial b_1} = \bar Y_1 \textbf{1}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;So our task is to find &lt;script type=&quot;math/tex&quot;&gt;\bar W_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\bar W_2&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Let’s start with &lt;script type=&quot;math/tex&quot;&gt;\bar W_2&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar W_2 = \bar Y_2 A_1 = \bar L \frac {\partial L}{\partial Y_2} A_1 = \frac {\partial L}{\partial Y_2} A_1&lt;/script&gt;

&lt;p&gt;We want to find &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial L}{\partial Y_2}&lt;/script&gt;. &lt;script type=&quot;math/tex&quot;&gt;Y_2&lt;/script&gt; is just an unnormalized score vector. In the following equations, we will set an alias &lt;script type=&quot;math/tex&quot;&gt;f  = Y_2&lt;/script&gt; for clarity. Consider first the data loss, &lt;script type=&quot;math/tex&quot;&gt;H_j = \frac{1}{N}\sum_i L_i = -\frac{1}{N}\sum_i log(p_j)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;When &lt;script type=&quot;math/tex&quot;&gt;j = y_i&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial H}{\partial f_{y_i}} = -\frac{1}{N} \sum_i \frac{\partial}{\partial f_{y_i}} log(p_{y_i}) \frac{\partial p_{y_i}}{\partial f_{y_i}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= -\frac{1}{N} \sum_i \frac{1}{p_{y_i}}  \frac{\sum_j e^{f_{j}} e^{f_{y_i}} - e^{f_{y_i}} e^{f_{y_i}} } {\sum_j e^{f_j}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= -\frac{1}{N} \sum_i \frac{1}{p_{y_i}} \frac{e^{f_{y_i}} (\sum_j e^{f_{j}}  - e^{f_{y_i}})}{\sum_j e^{f_j}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= -\frac{1}{N} \sum_i \frac{1}{p_{y_i}} p_{y_i}(1 - p_{y_i})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= p_{y_i} - 1&lt;/script&gt;

&lt;p&gt;When &lt;script type=&quot;math/tex&quot;&gt;j \neq y_i&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial H}{\partial f_{j}} = -\frac{1}{N} \sum_i \frac{\partial}{\partial f_{j}} log(p_{y_i}) \frac{\partial p_{y_i}}{\partial f_{j}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= -\frac{1}{N} \sum_i \frac{1}{p_{y_i}} \frac{0 - e^{f_{y_i}}e^{f_{j}}}{\sum_j e^{f_j}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= -\frac{1}{N} \sum_i \frac{1}{p_{y_i}} (- p_{y_i}p_j)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= p_j&lt;/script&gt;

&lt;p&gt;So this means:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\triangledown H_j =
\begin{cases}
  p_j &amp; \text{if } j\neq y_i \\    p_{j} - 1  &amp; \text{if } j=y_i\
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;In other words,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\triangledown H_k =  p_k - \mathbb{1}(k = y_i)&lt;/script&gt;

&lt;p&gt;Where &lt;script type=&quot;math/tex&quot;&gt;\mathbb{1}&lt;/script&gt; is just a binary indicator function that evaluates to 1 when the predicate is true.&lt;/p&gt;

&lt;p&gt;Now we can code the backpropagation onto the softmax loss function:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# backprop onto loss function&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Taking into account the gradient of the regularization term in &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\triangledown L = \frac{\triangledown H}{N} + \lambda\sum\limits_{i}\sum\limits_{j}W_{ij}&lt;/script&gt;

&lt;p&gt;We’ll add the regularization gradient at the end of the backpropagation.&lt;/p&gt;

&lt;p&gt;With the gradient of the loss function, we can easily calculate &lt;script type=&quot;math/tex&quot;&gt;\bar W_2&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\bar b_2&lt;/script&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# backprop onto W2 and b2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we have to compute &lt;script type=&quot;math/tex&quot;&gt;\bar W_1&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar W_2 = \bar Y_1 X  = \bar A_1 \frac{\partial A_1}{\partial Y_1} X = \bar Y_2 W_2 \frac{\partial A_1}{\partial Y_1} X&lt;/script&gt;

&lt;p&gt;To compute &lt;script type=&quot;math/tex&quot;&gt;\bar W_1&lt;/script&gt;, we first have to backpropagate onto the ReLU activation function. In other words, we have to find &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial A_1}{\partial Y_1}&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A_1 = max(0, Y_1) \implies \frac{\partial A_1}{\partial Y_1}=\mathbb{1}( Y_1 &gt;0)&lt;/script&gt;

&lt;p&gt;Combined with the chain rule, we see that the ReLU unit lets the gradient pass through unchanged if its input was greater than 0, but kills it if its input was less than zero during the forward pass.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# backprop onto ReLU activation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we can calculate &lt;script type=&quot;math/tex&quot;&gt;\bar W_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\bar b_1&lt;/script&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# backprop onto W1 and b2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;b1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Finally, remember to add in the backpropagation onto the regularization loss:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# don&#39;t forget regularization loss&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here’s the full code to compute the backpropagation on our network:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt;  &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## forward pass&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# first layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#  ReLU activation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# second layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# softmax&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## loss function&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_loss&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# backprop onto loss function&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# backprop onto W2 and b2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;b2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# backprop onto ReLU activation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dscores&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# backprop onto W1 and b2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;b1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dhidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# don&#39;t forget regularization loss&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;W1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We would use these gradients to then update &lt;script type=&quot;math/tex&quot;&gt;W_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;W_2&lt;/script&gt; with gradient descent.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Crash Course on Support Vector Machines</title>
   <link href="https://suchin.co/2017/03/04/The-Support-Vector-Machine/"/>
   <updated>2017-03-04T00:00:00-08:00</updated>
   <id>https://suchin.co/2017/03/04/The-Support-Vector-Machine</id>
   <content type="html">&lt;p&gt;The support vector machine (SVM) is one of the basic linear classifiers. This post will breakdown how the vanilla algorithm is implemented.&lt;/p&gt;

&lt;h2 id=&quot;basic-approach&quot;&gt;Basic approach&lt;/h2&gt;

&lt;p&gt;Let’s first get some preliminaries out of the way. Let &lt;script type=&quot;math/tex&quot;&gt;\{x_1,...,x_n\} \in X&lt;/script&gt; be a dataset describing our classification problem, and &lt;script type=&quot;math/tex&quot;&gt;\{w_1,...,w_n\} \in W&lt;/script&gt; be a weight matrix that we want to optimize. The SVM takes the data in &lt;script type=&quot;math/tex&quot;&gt;X \in \mathbb{R}^N&lt;/script&gt; and weights in &lt;script type=&quot;math/tex&quot;&gt;W \in \mathbb{R}^N&lt;/script&gt; to compute the vectors &lt;script type=&quot;math/tex&quot;&gt;W^TX&lt;/script&gt; of scores for each data sample per class. In other words, the value &lt;script type=&quot;math/tex&quot;&gt;w^T_jx_i&lt;/script&gt; denotes the score for j-th class for the i-th data sample. Suppose we are futher given the labels &lt;script type=&quot;math/tex&quot;&gt;\{y_1,...,y_n\}&lt;/script&gt; that specifies the &lt;em&gt;index&lt;/em&gt; of the correct class for each data sample. For example, &lt;script type=&quot;math/tex&quot;&gt;w^T_{y_i}x_i&lt;/script&gt; is the score for the &lt;em&gt;true&lt;/em&gt; class for the i-th data sample.&lt;/p&gt;

&lt;p&gt;The basic problem of the support vector machine is to find the best &lt;em&gt;hyperplane(s)&lt;/em&gt;, or subspace(s) of one less dimension than the ambient space, that best separate data points into distinct classes.&lt;/p&gt;

&lt;p&gt;How does one identify the optimal hyperplane? Well, every hyperplane can be written in the form:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^Tx_i=\text{b} \implies w^Tx_i - b = 0&lt;/script&gt;

&lt;p&gt;Where &lt;script type=&quot;math/tex&quot;&gt;w^Tx_i&lt;/script&gt; is some vector translated by the norm of &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;, called the bias term.&lt;/p&gt;

&lt;p&gt;The SVM amounts to finding hyperplanes such that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^T_{j}x_i - w^T_{y_i}x_i  - b  \ge \delta \text{   } \forall  \text{   }  j \neq y_i&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\delta&lt;/script&gt; is called the &lt;em&gt;margin&lt;/em&gt;, and corresponds to the euclidean distance between the separating hyperplanes. We essentially don’t want data points to fall inside the margin, and the optimal decision boundary lies at the midpoint of the margin.&lt;/p&gt;

&lt;p&gt;This is an example of a &lt;em&gt;soft margin&lt;/em&gt; SVM. There is also a &lt;em&gt;hard margin&lt;/em&gt; version, in which the margin is completely determined by the closest data-points to the decision boundary,  called the &lt;em&gt;support vectors&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20170304/svm.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that it can be shown that the canonical binary classification SVM problem is just a special case of the multi-class formulation above. In particular, it can be shown that in the binary case the above formulation reduces to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;sgn(w^Tx_i - b) \ge \delta&lt;/script&gt;

&lt;p&gt;Finally, note that from here on out we will disregard the bias term &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; in the above formulation, and will assume that the bias term is incorporated into the weight matrix &lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt; as an extra column.&lt;/p&gt;

&lt;h2 id=&quot;loss-function&quot;&gt;Loss Function&lt;/h2&gt;

&lt;p&gt;Now that we’ve defined the general approach to classifying data with the SVM, we have to derive the loss function for the problem, which enforces how weights &lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt; get updated during learning.&lt;/p&gt;

&lt;p&gt;The SVM aims to minimize the following loss function &lt;script type=&quot;math/tex&quot;&gt;L_i&lt;/script&gt; for each data sample &lt;script type=&quot;math/tex&quot;&gt;x_i \in X&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_i = \sum\limits_{j \neq y_i} max (0, w^T_{j}x_i - w^T_{y_i}x_i + \delta)&lt;/script&gt;

&lt;p&gt;Essentially, we’re saying that we incur loss if the difference between the scores of the correct class and those of the incorrect classes are within some margin of each other. However, once that difference passes the threshold of the margin, we always incur zero loss.&lt;/p&gt;

&lt;p&gt;The loss function scales with:
  1) the size of the margin and
  2) how much smaller the score at the index of the incorrect class is to the score at the index of the correct class.&lt;/p&gt;

&lt;p&gt;This implies that the SVM’s output are  uncalibrated scores that roughly relate to &lt;em&gt;center of mass&lt;/em&gt; of the score vector. We want the score vector for the i-th data sample to be highly concentrated at the index of the correct class.&lt;/p&gt;

&lt;h2 id=&quot;regularization&quot;&gt;Regularization&lt;/h2&gt;

&lt;p&gt;We enforce preference over particular weights during optimization through &lt;em&gt;regularization&lt;/em&gt;, an extra term that we add to the loss function above:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R(W) = \lambda \sum\limits_{j}\sum\limits_{i}W_{ij}^2&lt;/script&gt;

&lt;p&gt;Because we are using the &lt;script type=&quot;math/tex&quot;&gt;L_2&lt;/script&gt;-norm (i.e. the global sum of the squared matrix), &lt;script type=&quot;math/tex&quot;&gt;R(W)&lt;/script&gt; is called &lt;script type=&quot;math/tex&quot;&gt;L_2&lt;/script&gt; regularization. The &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; term is called the &lt;em&gt;regularization constant&lt;/em&gt;, which is a hyperparameter we can optimize empirically.&lt;/p&gt;

&lt;p&gt;The loss function for each data sample now looks like this:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_i = \sum\limits_{j \neq y_i} max (0, w^T_{j}x_i - w^T_{y_i}x_i + \delta) + \lambda\sum\limits_{j}\sum\limits_{i}W_{ij}^2&lt;/script&gt;

&lt;p&gt;By adding the regularization term to the loss function, we are saying that we prefer score vectors that have a lower &lt;script type=&quot;math/tex&quot;&gt;L_2&lt;/script&gt;-norm, which  corresponds to scores that are &lt;em&gt;lower and diffuse&lt;/em&gt;. Lower, diffuse scores improve model generalization because a single dimension doesn’t have overwhelming contribution to the overall prediction.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20170304/reg.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The final loss function for the SVM is just the average loss over &lt;em&gt;all&lt;/em&gt; data samples:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \frac{1}{N}\sum\limits_iL_i + R(W) = \frac{1}{N}\sum\limits_i\sum\limits_{j \neq y_i} max (0, w^T_{j}x_i - w^T_{y_i}x_i + \delta) + \lambda\sum\limits_{i}\sum\limits_{j}W_{ij}^2&lt;/script&gt;

&lt;p&gt;Here’s the code for the SVM loss function in Python:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;svm_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## number training samples&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;num_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## get scores&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# calculate margins&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# margins at the index of the correct class should be zero&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# calculate l2 regularization&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;l2_reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# average over all samples&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;data_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_train&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2_reg&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;optimization-step&quot;&gt;Optimization step&lt;/h2&gt;

&lt;p&gt;Now that we have defined the loss function for the SVM, how do we update the weights &lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt; to minimize loss?&lt;/p&gt;

&lt;p&gt;First we calculate the gradient of &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; with respect to our weights &lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;. Then, we update our weights to descend along our loss function in the steepest direction. We can scale how large of a step size we take along the gradient with a &lt;em&gt;learning rate&lt;/em&gt; parameter.&lt;/p&gt;

&lt;p&gt;With respect to the SVM, we first take the derivative of its loss function, which involves taking the derivative of the &lt;script type=&quot;math/tex&quot;&gt;max(0, -)&lt;/script&gt; function. That may sound scary, but it’s actually pretty easy once you split out the possible ranges of the function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
H_i = \sum\limits_{j \neq y_i}max (0, w_{j}^Tx_i- w_{y_i}^Tx_i + \delta) = \left\{\begin{aligned}
&amp; 0 &amp;&amp;: \text{if score outside margin} \\
&amp;w^T_{j}x_i - w^T_{y_i}x_i + \delta &amp;&amp;:  \text{if score inside margin}
\end{aligned}
\right. %]]&gt;&lt;/script&gt;

&lt;p&gt;Let’s look at a simple scenario to see what the derivative would look like, and generalize from there.&lt;/p&gt;

&lt;p&gt;Suppose we had a three dimensional weight vector &lt;script type=&quot;math/tex&quot;&gt;\{w_1,w_2,w_3\}&lt;/script&gt; that we wanted to optimize with respect to the data sample &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;, and let’s suppose that of the three classes &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; could map to, the 2nd class was the true class. &lt;script type=&quot;math/tex&quot;&gt;H_i&lt;/script&gt; would then expand to:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H_i = \sum\limits_{j \neq y_i} max (0, w^T_{j}x_i - w^T_{y_i}x_i + \delta)\\
 = max (0, w^T_{1}x_i - w^T_{2}x_i + \delta) + max (0, w^T_{3}x_i - w^T_{2}x_i + \delta)\\
 = [w^T_{1}x_i - w^T_{2}x_i + \delta &gt; 0] (w^T_{1}x_i - w^T_{2}x_i + \delta)  + [w^T_{3}x_i - w^T_{2}x_i + \delta &gt; 0] (w^T_{3}x_i - w^T_{2}x_i + \delta)&lt;/script&gt;

&lt;p&gt;Then we take the derivative of &lt;script type=&quot;math/tex&quot;&gt;L_i&lt;/script&gt; with respect to &lt;script type=&quot;math/tex&quot;&gt;w_2&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\{w_1, w_3\}&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{dH_i}{dw_{2}} = -x([w^T_{1}x_i - w^T_{2}x_i + \delta &gt; 0] + [w^T_{3}x_i - w^T_{2}x_i + \delta &gt; 0])\\
\frac{dH_i}{dw_{1}} = x([w^T_{1}x_i - w^T_{2}x_i + \delta &gt; 0])\\
\frac{dH_i}{dw_{3}} = x([w^T_{3}x_i - w^T_{2}x_i + \delta &gt; 0])&lt;/script&gt;

&lt;p&gt;Not so bad!&lt;/p&gt;

&lt;p&gt;We can generalize the above procedure as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{dH_i}{dW_{y_i}} = -x(\sum\limits_{j \neq y_i}[w^Tx_j - w_{y_i}^Tx + \delta &gt; 0])\\
  \frac{dH_i}{dW_{j}} =x(w^T_jx - w_{y_i}^Tx + \delta &gt; 0)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;j \neq y_i&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;In simple words, the gradient amounts to counting the number of times an class prediction falls within the margins of our decision boundary, scaled by &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;In its entirety, the gradient of the loss function is the average gradient across all samples, also taking into account the regularization term:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\triangledown L = \frac{1}{N}\sum\limits_i[\frac{dH_i}{dW_{y_i}} + \frac{dH_i}{dW_{j}}] + \lambda\sum\limits_{i}\sum\limits_{j}W_{ij}&lt;/script&gt;

&lt;p&gt;Here’s the code for computing the gradient for the SVM:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## get number of training samples&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;num_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## compute number of errors&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;num_errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## compute derivative&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## for dH/dWj where j != y&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## for DH/dWy&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_errors&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;dLdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dLdW&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To do the weight update, we perform the simple procedure:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;## compute loss and margins&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svm_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;## compute gradient&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dLdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dLdW&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;## compute loss and gradient&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dLdW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;## update weights&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dLdW&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Finally, we can create a vanilla SVM training function by initializing &lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt; with random values:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## get appropriate dimensions&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## initialize W with random values&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;## repeat update&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;curr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;curr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;curr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As a side note, in the real world, instead of computing the gradient over the &lt;em&gt;entire&lt;/em&gt; training dataset, we compute gradients over subsamples. This is just more efficient for large scale applications in which the entire dataset isn’t necessary to make a single step along the gradient of the loss function.&lt;/p&gt;

&lt;h2 id=&quot;advantages-and-issues&quot;&gt;Advantages and Issues&lt;/h2&gt;

&lt;p&gt;As with all other learning algorithms, the SVM has strengths and weaknesses.&lt;/p&gt;

&lt;p&gt;First off, one big issue with the SVM is that its scores can be difficult to interpret. Because they are uncalibrated scores, it’s hard to compare them.&lt;/p&gt;

&lt;p&gt;Futhermore, in principle SVMs should be highly resistant to over-fitting, due to things like regularization and margins, but in practice this depends on the careful choice of these hyperparameters, which is pretty nontrivial.&lt;/p&gt;

&lt;p&gt;However, the SVM (especially the hard-margin version) is more memory efficient than other algorithms because it primarily optimizes the classifier based on euclidean distance between support vectors, a small subset of the data. Furthermore, if a data point is outside of the margin, loss is zero no matter what. That means that the algorithm is less sensitive to outliers in the dataset.&lt;/p&gt;

&lt;p&gt;Finally, for simplicity we have only considered the linear SVM here, but there are a multitude of non-linear and kernel-based SVMs that can fit quite intricate decision boundaries to the data. In fact, the SVM is pretty versatile once kernels are introduced.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Introducing Utah</title>
   <link href="https://suchin.co/2016/12/28/Introducing-Utah/"/>
   <updated>2016-12-28T00:00:00-08:00</updated>
   <id>https://suchin.co/2016/12/28/Introducing-Utah</id>
   <content type="html">&lt;p&gt;Recently, I’ve been working on a Rust crate for tabular data manipulation. I’m excited to share the current state of the project.&lt;/p&gt;

&lt;h2 id=&quot;a-dataframe-for-rust&quot;&gt;A dataframe for Rust&lt;/h2&gt;

&lt;p&gt;Languages like &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;Python&lt;/a&gt;, &lt;a href=&quot;http://www.r-tutor.com/r-introduction/data-frame&quot;&gt;R&lt;/a&gt;, and &lt;a href=&quot;https://github.com/JuliaStats/DataFrames.jl&quot;&gt;Julia&lt;/a&gt; have popularized the  &lt;em&gt;dataframe&lt;/em&gt;, which is an abstraction over a collection of &lt;em&gt;named&lt;/em&gt; arrays. The dataframe allows users to access, transform, and compute over two-dimensional data that may have mixed types.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/pegasos1/utah&quot;&gt;&lt;strong&gt;Utah&lt;/strong&gt;&lt;/a&gt; is a dataframe crate backed by &lt;a href=&quot;https://github.com/bluss/rust-ndarray&quot;&gt;ndarray&lt;/a&gt; for type-conscious tabular data manipulation with an expressive, functional interface.&lt;/p&gt;

&lt;h2 id=&quot;overall-goals-of-project&quot;&gt;Overall goals of project&lt;/h2&gt;

&lt;h4 id=&quot;functional-interface-to-transform-data&quot;&gt;Functional interface to transform data&lt;/h4&gt;

&lt;p&gt;Transformations are composable, repeatable, and readable.&lt;/p&gt;

&lt;h4 id=&quot;iterator-adapter-implementations-for-performance-and-laziness&quot;&gt;Iterator adapter implementations for performance and laziness&lt;/h4&gt;

&lt;p&gt;Data transformations are implemented with Rust’s iterators, which are fast, safe, and lazy.&lt;/p&gt;

&lt;h4 id=&quot;leverage-reference-locality-for-performance&quot;&gt;Leverage reference locality for performance&lt;/h4&gt;

&lt;p&gt;Most implementations of the dataframe involve some sort of map between column names and the underlying data. So during computations, you’re likely incurring performance hits while chasing pointers around in memory. In particular, row-wise operations can be much slower than column-wise ones.&lt;/p&gt;

&lt;p&gt;I wanted to explore the effects of keeping data close together in memory. This crate is backed by ndarray to hold data, and enums to support mixed types. At the end of this post, I’ll describe an alternate implementation that sacrifices data locality to be able to have mixed types without wrappers.&lt;/p&gt;

&lt;h4 id=&quot;solid-error-handling&quot;&gt;Solid error handling&lt;/h4&gt;

&lt;p&gt;There are many errors that can occur while querying dataframes. For example, imagine selecting a column that doesn’t exist, or joining two dataframes that don’t have a common key. Such simple errors can be hidden in a sea of complex data transformations. The goal here is to provide compile-time error handling of these sorts of mistakes. I explore potential avenues to accomplish this goal at the end of this post.&lt;/p&gt;

&lt;h2 id=&quot;internals&quot;&gt;Internals&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Note: The internals of the project are subject to alter in the future; I’ll try to keep an updated post describing changes.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-dataframe&quot;&gt;The DataFrame&lt;/h3&gt;

&lt;p&gt;There are two core types in Utah: the &lt;strong&gt;DataFrame&lt;/strong&gt; and the &lt;strong&gt;DataFrameIterator&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Utah dataframes are defined as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UtahNum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;c&quot;&gt;// ^ math ops like Add/Mul/etc, Empty, and others.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Matrix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; takes the generic parameter &lt;em&gt;T&lt;/em&gt;, which corresponds to the type of data in the inner matrix.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; is read-only by default. To operate on a dataframe that is read-write, you can use a &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrameMut&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub struct DataFrameMut&amp;lt;&#39;a, T&amp;gt;
    where T: &#39;a + UtahNum
{
    pub columns: Vec&amp;lt;String&amp;gt;,
    pub data: MatrixMut&amp;lt;&#39;a, T&amp;gt;,
    pub index: Vec&amp;lt;String&amp;gt;,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The only thing we’ve changed is the &lt;code class=&quot;highlighter-rouge&quot;&gt;data&lt;/code&gt; field – from a &lt;code class=&quot;highlighter-rouge&quot;&gt;Matrix&amp;lt;T&amp;gt;&lt;/code&gt; to a &lt;code class=&quot;highlighter-rouge&quot;&gt;MatrixMut&amp;lt;T&amp;gt;&lt;/code&gt;. For simplicity, we’ll disregard the mutable dataframe for the rest of this post, but know that everything we talk about below extends to the mutable variant.&lt;/p&gt;

&lt;p&gt;The inner data is of type &lt;code class=&quot;highlighter-rouge&quot;&gt;Matrix&amp;lt;T&amp;gt;&lt;/code&gt;, an alias to a &lt;a href=&quot;http://bluss.github.io/rust-ndarray/master/ndarray/type.Array2.html&quot;&gt;2-D array&lt;/a&gt; from the ndarray crate.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Matrix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Array2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The data that the Matrix contains implement all the traits associated with the custom trait &lt;em&gt;UtahNum&lt;/em&gt; (ie &lt;code class=&quot;highlighter-rouge&quot;&gt;Add&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;Sub&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;Mul&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;Div&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;One&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Zero&lt;/code&gt;) for computations, as well as the custom trait &lt;em&gt;Empty&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Empty values are an unfortunate reality of most datasets, and manifest itself in different types depending on the context. For example, empty values may be &lt;code class=&quot;highlighter-rouge&quot;&gt;NAN&lt;/code&gt; if you’re working with float data, an empty string with &lt;code class=&quot;highlighter-rouge&quot;&gt;String&lt;/code&gt; data, or &lt;code class=&quot;highlighter-rouge&quot;&gt;0&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;Int&lt;/code&gt; data. We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;Empty&lt;/code&gt; trait to define empty values for any type we want to use in a dataframe:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;is_empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We ask, for type &lt;code class=&quot;highlighter-rouge&quot;&gt;T&lt;/code&gt;, what should we consider as an empty value, and when is a value equal to empty? In the case of &lt;code class=&quot;highlighter-rouge&quot;&gt;f64&lt;/code&gt;, we might implement the trait as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f64&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f64&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;NAN&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;is_empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.is_nan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The columns/index are just names of the columns and rows of the dataframe, respectively.&lt;/p&gt;

&lt;h3 id=&quot;the-dataframeiterator&quot;&gt;The DataFrameIterator&lt;/h3&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrameIterator&lt;/code&gt; is what we use to perform transformations and computations. The &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrameIterator&lt;/code&gt; is of the following type:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub struct DataFrameIterator&amp;lt;&#39;a, I, T: &#39;a&amp;gt;
    where I: Iterator&amp;lt;Item = Window&amp;lt;&#39;a, T&amp;gt;&amp;gt;
{
    pub names: Iter&amp;lt;&#39;a, String&amp;gt;,
    pub data: I,
    pub other: Vec&amp;lt;String&amp;gt;,
    pub axis: UtahAxis,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;First up, notice that we’ve now got lifetimes in the type. The DataFrameIterator is just a reference to a dataframe that owns the original data, and cannot outlive it. Ideally, you’ll have to read the data into memory only once.&lt;/p&gt;

&lt;p&gt;Next, the trait bound on the dataframe iterator is &lt;code class=&quot;highlighter-rouge&quot;&gt;Iterator&amp;lt;Item = Window&amp;lt;&#39;a, T&amp;gt;&amp;gt;&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;Window&amp;lt;&#39;a, T&amp;gt;&lt;/code&gt; is another type alias:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub type Window&amp;lt;&#39;a, T&amp;gt; = (String, ArrayView1&amp;lt;&#39;a, T&amp;gt;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;ArrayView1&lt;/code&gt; &lt;a href=&quot;`http://bluss.github.io/rust-ndarray/master/ndarray/type.ArrayView1.html`&quot;&gt;type&lt;/a&gt; is a column or row slice of the original data. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Iterator&lt;/code&gt; bound tells us that the &lt;code class=&quot;highlighter-rouge&quot;&gt;DataframeIterator&lt;/code&gt; iterates over &lt;em&gt;views&lt;/em&gt; of the data, along with their names (i.e. a column or index value).  The dataframe lives in a contiguous area of memory, and to iterate over it, we just slide a window over the stride of the vector that represents the matrix containing the data. The iterator is realized through ndarray’s &lt;code class=&quot;highlighter-rouge&quot;&gt;AxisIter&lt;/code&gt;&lt;a href=&quot;&amp;quot;http://bluss.github.io/rust-ndarray/master/ndarray/struct.AxisIter.html&amp;quot;&quot;&gt;type&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the struct fields:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;data&lt;/code&gt; just houses the iterator over the “windows” we just discussed.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;axis&lt;/code&gt; tells the dataframe iterator which direction you want to iterate over. This field is of type &lt;code class=&quot;highlighter-rouge&quot;&gt;UtahAxis&lt;/code&gt;, an enum over two different directions of iteration:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;enum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UtahAxis&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;names&lt;/code&gt; is an iterator over the axis label (index or columns) you’re iterating over.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;other&lt;/code&gt; is the axis label that you’re &lt;em&gt;not&lt;/em&gt; iterating over. We just hold onto this value in case you want to allocate the transformation into a new dataframe.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;creating-a-dataframe&quot;&gt;Creating a dataframe&lt;/h2&gt;

&lt;p&gt;There are multiple ways to create a dataframe. The most straightforward way is to use a &lt;em&gt;builder pattern&lt;/em&gt;, which allows you to overwrite individual fields of the dataframe successively:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
use utah::prelude::*;
let c = arr2(&amp;amp;[[2., 6.], [3., 4.], [2., 1.]]);
let df: DataFrame&amp;lt;f64&amp;gt; = DataFrame::new(c)
                                  .columns(&amp;amp;[&quot;a&quot;, &quot;b&quot;])?
                                  .index(&amp;amp;[&quot;1&quot;, &quot;2&quot;, &quot;3&quot;])?;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt; operator, newly introduced syntax for accessing the &lt;code class=&quot;highlighter-rouge&quot;&gt;Result&lt;/code&gt; type, is there to prevent you from adding columns or indices that don’t match the dimensions of the underlying data.&lt;/p&gt;

&lt;p&gt;There’s also &lt;code class=&quot;highlighter-rouge&quot;&gt;dataframe!&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;col!&lt;/code&gt; macros which you can use to create new dataframes on the fly:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let k: DataFrame&amp;lt;f64&amp;gt; = dataframe!(
    {
        &quot;a&quot; =&amp;gt;  col!([2., 3., 2.]),
        &quot;b&quot; =&amp;gt;  col!([2., NAN, 2.])
    });
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Finally, you can import data from a CSV.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let file_name = &quot;test.csv&quot;;                            
let df: Result&amp;lt;DataFrame&amp;lt;InnerType&amp;gt;&amp;gt; = DataFrame::read_csv(file_name);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Note that Utah’s &lt;code class=&quot;highlighter-rouge&quot;&gt;ReadCSV&lt;/code&gt; trait is pretty barebones right now.&lt;/p&gt;

&lt;h3 id=&quot;combinators&quot;&gt;Combinators&lt;/h3&gt;

&lt;p&gt;The user interacts with Utah dataframes by chaining combinators, which are adapters over the dataframe iterator. Each operation is lazy by default. You can chain as many combinators as you want, but it won’t do anything until you invoke a collection operation like &lt;code class=&quot;highlighter-rouge&quot;&gt;as_df&lt;/code&gt;, which would allocate the results into a new dataframe, or &lt;code class=&quot;highlighter-rouge&quot;&gt;as_matrix&lt;/code&gt;, which would allocate the results into a 2-D ndarray.&lt;/p&gt;

&lt;p&gt;I’ve organized the combinators that I’ve built so far into four different types, but there are naturally many more. The nice thing is that the iterator adapter design makes it extremely easy to add new combinators to the project.&lt;/p&gt;

&lt;h4 id=&quot;transform-combinators&quot;&gt;Transform combinators&lt;/h4&gt;

&lt;p&gt;These combinators are meant for changing the shape of the data you’re working with. Combinators in this class include &lt;code class=&quot;highlighter-rouge&quot;&gt;select&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;remove&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;append&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let a = arr2(&amp;amp;[[2.0, 7.0], [3.0, 4.0], [2.0, 8.0]]);
let df = DataFrame::new(a).index(&amp;amp;[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]).unwrap();
let res = df.select(&amp;amp;[&quot;a&quot;, &quot;c&quot;], UtahAxis::Row);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;process-combinators&quot;&gt;Process combinators&lt;/h4&gt;

&lt;p&gt;Process combinators are meant for changing the original data you’re working with. Combinators in this class include &lt;code class=&quot;highlighter-rouge&quot;&gt;impute&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;mapdf&lt;/code&gt;. Impute replaces missing values of a dataframe with the mean of the corresponding axis. Note that these operations require the use of a &lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrameMut&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let mut a: DataFrameMut&amp;lt;f64&amp;gt; = dataframe!(
    {
        &quot;a&quot; =&amp;gt;  col!([NAN, 3., 2.]),
        &quot;b&quot; =&amp;gt;  col!([2., NAN, 2.])
    });
let res = df.impute(ImputeStrategy::Mean, UtahAxis::Column);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;interact-combinators&quot;&gt;Interact combinators&lt;/h4&gt;

&lt;p&gt;Interact combinators are meant for interactions between dataframes. They generally take at least two dataframe arguments. Combinators in this class include &lt;code class=&quot;highlighter-rouge&quot;&gt;inner_left_join&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;outer_left_join&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;inner_right_join&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;outer_right_join&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;concat&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let a: DataFrame&amp;lt;f64&amp;gt; = dataframe!(
    {
        &quot;a&quot; =&amp;gt;  column!([NAN, 3., 2.]),
        &quot;b&quot; =&amp;gt;  column!([2., NAN, 2.])
    });
let b: DataFrame&amp;lt;f64&amp;gt; = dataframe!(
    {
        &quot;b&quot; =&amp;gt;  column!([NAN, 3., 2.]),
        &quot;c&quot; =&amp;gt;  column!([2., NAN, 2.])
    });
let res = a.inner_left_join(&amp;amp;b).as_df()?;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;aggregate-combinators&quot;&gt;Aggregate combinators&lt;/h4&gt;

&lt;p&gt;Aggregate combinators are meant to reduce a chain of combinators to some result. These combinators are usually the last operation in a chain, but don’t necessarily have to be. Combinators in this class include &lt;code class=&quot;highlighter-rouge&quot;&gt;sumdf&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;mindf&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;maxdf&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;stdev&lt;/code&gt; (standard deviation), and &lt;code class=&quot;highlighter-rouge&quot;&gt;mean&lt;/code&gt;. Currently, aggregate combinators are not iterator collection operations, because they do not invoke a chain. This may change in the future.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let a = arr2(&amp;amp;[[2.0, 7.0], [3.0, 4.0], [2.0, 8.0]]);
let df = DataFrame::new(a).index(&amp;amp;[1, 2, 3])?.columns(&amp;amp;[&quot;a&quot;, &quot;b&quot;])?;
let res = df.mean(UtahAxis::Row);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;chaining-combinators&quot;&gt;Chaining combinators&lt;/h4&gt;

&lt;p&gt;The real power of combinators comes from the ability to chain them together in expressive transformations that are easy to parse. You can do things like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let result = df.df_iter(UtahAxis::Row)
               .remove(&amp;amp;[&quot;1&quot;])
               .select(&amp;amp;[&quot;2&quot;])
               .append(&quot;8&quot;, new_data.view())
               .inner_left_join(df_1)
               .sumdf()
               .as_df()?
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Because we’ve built the chain on a row-wise dataframe iterator, each subsequent operation will only operate on the rows of the dataframe.&lt;/p&gt;

&lt;h2 id=&quot;creating-new-combinators&quot;&gt;Creating new combinators&lt;/h2&gt;

&lt;p&gt;Rust’s trait system allows for repeatable patterns throughout the project, especially when it comes to designing combinators. By following these steps, you can easily add your own combinators for new transformations or computations.&lt;/p&gt;

&lt;h5 id=&quot;define-a-new-struct-combinator-with-necessary-data&quot;&gt;1. Define a new struct &lt;code class=&quot;highlighter-rouge&quot;&gt;Combinator&lt;/code&gt;, with necessary data.&lt;/h5&gt;

&lt;p&gt;The combinator should contain an iterator over items of type &lt;code class=&quot;highlighter-rouge&quot;&gt;Window&amp;lt;&#39;a, T&amp;gt;&lt;/code&gt; – a matrix slice and its name.  &lt;code class=&quot;highlighter-rouge&quot;&gt;Sum&lt;/code&gt; contains the Iterator, the axis label it’s not iterating over, and the axis of iteration.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    pub struct Sum&amp;lt;&#39;a, I: &#39;a, T: &#39;a, S&amp;gt;
      where I: Iterator&amp;lt;Item = Window&amp;lt;&#39;a, T&amp;gt;&amp;gt; + &#39;a,
            T: UtahNum,
            S: Identifier
  {
      data: I,
      other: Vec&amp;lt;String&amp;gt;,
      axis: UtahAxis,
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h5 id=&quot;impl-iterator-for-combinator&quot;&gt;2. impl Iterator for Combinator&lt;/h5&gt;

&lt;p&gt;What’s the output of this combinator during iteration over the dataframe? In the case of &lt;code class=&quot;highlighter-rouge&quot;&gt;Sum&lt;/code&gt;, we’re just taking the scalar sum of elements in a “window”.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      impl&amp;lt;&#39;a, I, T&amp;gt; Iterator for Sum&amp;lt;&#39;a, I, T&amp;gt;
        where I: Iterator&amp;lt;Item = Window&amp;lt;&#39;a, T&amp;gt;&amp;gt;,
              T: UtahNum    
    {
        type Item = T;
        fn next(&amp;amp;mut self) -&amp;gt; Option&amp;lt;Self::Item&amp;gt; {
            match self.data.next() {
                None =&amp;gt; return None,
                Some((_, dat)) =&amp;gt; return Some(dat.scalar_sum()),
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h5 id=&quot;add-impl-combinator-with-a-fn-new&quot;&gt;3. Add &lt;code class=&quot;highlighter-rouge&quot;&gt;impl Combinator&lt;/code&gt; with a &lt;code class=&quot;highlighter-rouge&quot;&gt;fn new()&lt;/code&gt;.&lt;/h5&gt;

&lt;p&gt;How do you create this combinator from scratch? That’s easy:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      impl&amp;lt;&#39;a, I, T&amp;gt; Sum&amp;lt;&#39;a, I, T&amp;gt;
        where I: Iterator&amp;lt;Item = Window&amp;lt;&#39;a, T&amp;gt;&amp;gt;,
              T: UtahNum
    {
        pub fn new(df: I, other: Vec&amp;lt;String&amp;gt;, axis: UtahAxis) -&amp;gt; Sum&amp;lt;&#39;a, I, T&amp;gt; {
            Sum {
                data: df,
                other: other,
                axis: axis,
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h5 id=&quot;add-fn-combinatorself--iterator-to-its-categorical-trait&quot;&gt;4. Add &lt;code class=&quot;highlighter-rouge&quot;&gt;fn combinator(self : Iterator)&lt;/code&gt; to its categorical trait&lt;/h5&gt;

&lt;p&gt;The function you add should invoke the &lt;code class=&quot;highlighter-rouge&quot;&gt;new&lt;/code&gt; constructor defined in the third step. In the case of &lt;code class=&quot;highlighter-rouge&quot;&gt;Sum&lt;/code&gt;, we’ll add it to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Aggregate&lt;/code&gt; trait. Define a new categorical trait if the new combinator doesn’t fit with the built-in ones.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub trait Aggregate&amp;lt;&#39;a, T&amp;gt;
    where T: UtahNum
  {
    fn sumdf(self) -&amp;gt; Sum&amp;lt;&#39;a, Self, T&amp;gt;
        where Self: Sized + Iterator&amp;lt;Item = Window&amp;lt;&#39;a, T&amp;gt;&amp;gt;;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h5 id=&quot;add-fn-combinatorself--dataframe-to-the-operations-trait&quot;&gt;5. Add &lt;code class=&quot;highlighter-rouge&quot;&gt;fn combinator(self : DataFrame)&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Operations&lt;/code&gt; trait&lt;/h5&gt;

&lt;p&gt;The function you add should invoke the combinator from an allocated dataframe.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  pub trait Operations&amp;lt;&#39;a, T&amp;gt;
    where T: &#39;a + UtahNum
  {
    fn sumdf(&amp;amp;&#39;a mut self, axis: UtahAxis) -&amp;gt; SumIter&amp;lt;&#39;a, T&amp;gt;;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SumIter&lt;/code&gt; is another alias:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub type SumIter&amp;lt;&#39;a, T&amp;gt; = Sum&amp;lt;&#39;a, DataFrameIterator&amp;lt;&#39;a, T&amp;gt;, T&amp;gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h5 id=&quot;impl-asdataframe-for-combinator&quot;&gt;6. impl AsDataFrame for Combinator&lt;/h5&gt;

&lt;p&gt;The function you add will let you go from the &lt;code class=&quot;highlighter-rouge&quot;&gt;Combinator&lt;/code&gt; iterator to an allocated dataframe/matrix/array. Read next section for more details on this trait.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  pub trait ToDataFrame&amp;lt;&#39;a, I, T&amp;gt;
    where T: UtahNum + &#39;a
  {
          fn as_df(self) -&amp;gt; Result&amp;lt;DataFrame&amp;lt;T&amp;gt;&amp;gt; where Self: Sized + Iterator&amp;lt;Item = I&amp;gt;;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It’s interesting to think about how to reduce combinators to iterators adapters that we’re familiar with. For example, the &lt;code class=&quot;highlighter-rouge&quot;&gt;concat&lt;/code&gt; combinator is just a &lt;code class=&quot;highlighter-rouge&quot;&gt;Chain&lt;/code&gt;. More complicated combinators like &lt;code class=&quot;highlighter-rouge&quot;&gt;Groupby&lt;/code&gt; can be thought of as a &lt;code class=&quot;highlighter-rouge&quot;&gt;Map&lt;/code&gt; on a &lt;code class=&quot;highlighter-rouge&quot;&gt;Filter&lt;/code&gt;. These conceptual relationships can help you think about how to best implement a new combinator.&lt;/p&gt;

&lt;h3 id=&quot;collection&quot;&gt;Collection&lt;/h3&gt;

&lt;p&gt;There are many ways you can access or store the result of your chained operations. Because each data transformation is just an iterator, we can naturally collect the output of chained operations via &lt;code class=&quot;highlighter-rouge&quot;&gt;collect()&lt;/code&gt; or a &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loop:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for x in df.concat(&amp;amp;df_1) {
   println!(&quot;{:?}&quot;, x)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;But we also have an &lt;code class=&quot;highlighter-rouge&quot;&gt;ToDataFrame&lt;/code&gt; trait, which dumps the output of chained combinators into a new dataframe, matrix, or array, so we can do something like the following:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let maximum_values = df.concat(&amp;amp;df_1).maxdf(UtahAxis::Column).as_df()?;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;the-innertype&quot;&gt;The InnerType&lt;/h3&gt;

&lt;p&gt;Now, I mentioned in the beginning that most dataframes provide mixed types, and I wanted to provide a similar functionality here. In the module &lt;code class=&quot;highlighter-rouge&quot;&gt;utah::mixedtypes&lt;/code&gt;, I’ve defined &lt;code class=&quot;highlighter-rouge&quot;&gt;InnerType&lt;/code&gt;, which is an enum over various types of data that can co-exist in the same dataframe:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub enum InnerType {
    Float(f64),
    Int64(i64),
    Int32(i32),
    Str(String),
    Empty,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;With this wrapper, you can have &lt;code class=&quot;highlighter-rouge&quot;&gt;String&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;f64&lt;/code&gt; in the same dataframe.&lt;/p&gt;

&lt;p&gt;In general, this may not be the best approach to supporting mixed types in this project, because there are performance hits for computation when working with type wrappers. I discuss alternative avenues to achieving this goal below.&lt;/p&gt;

&lt;p&gt;An important consequence of supporting mixed types is that because strings are not &lt;code class=&quot;highlighter-rouge&quot;&gt;Copy&lt;/code&gt;, the dataframe is not &lt;code class=&quot;highlighter-rouge&quot;&gt;Copy&lt;/code&gt;. This means that you may run into unexpected ownership problems while building data transformations. There are some API ergonomics to be ironed out.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;

&lt;p&gt;Next, I’ll catalog some of the thoughts on future directions for this project.&lt;/p&gt;

&lt;h4 id=&quot;comparing-a-map-implementation-to-a-reference-local-one&quot;&gt;Comparing a map implementation to a reference-local one&lt;/h4&gt;

&lt;p&gt;There are some drawbacks to the iterator adapter design which may warrant re-visiting the map implementation I mentioned in the beginning of the post. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;select&lt;/code&gt; is currently &lt;code class=&quot;highlighter-rouge&quot;&gt;O(n)&lt;/code&gt; when it could be &lt;code class=&quot;highlighter-rouge&quot;&gt;O(1)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Furthermore, we have to wrap our data with an enum (ie &lt;code class=&quot;highlighter-rouge&quot;&gt;InnerType&lt;/code&gt;) to be able to support mixed types in the same array. Computations are not as fast as they could be.&lt;/p&gt;

&lt;p&gt;Ideally, we could work with raw types directly. An alternate dataframe implementation sacrifices reference locality for the ability to work with raw types in the mixed-context.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MixedDataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UtahNum&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Array1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This dataframe’s design implies that we will need two separate types for row-wise and column-wise iteration.&lt;/p&gt;

&lt;p&gt;Row-wise iteration would could be a multi-zip operation where we connect each value of the same index across all columns.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub struct MixedDataFrameRowIterator&amp;lt;&#39;a, T: &#39;a&amp;gt;
    where T: UtahNum
          Zip&amp;lt;AxisIter&amp;lt;&#39;a, T, usize&amp;gt;&amp;gt;: Iterator
{
    pub names: Iter&amp;lt;&#39;a, String&amp;gt;,
    pub data: Zip&amp;lt;AxisIter&amp;lt;&#39;a, T, usize&amp;gt;&amp;gt;,
    pub other: Vec&amp;lt;String&amp;gt;,
    pub axis: UtahAxis,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;On the other hand, column-wise iteration could be an iterator over the HashMap.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub struct MixedDataFrameColIterator&amp;lt;&#39;a, T: &#39;a&amp;gt;
    where T: UtahNum
          Iter&amp;lt;&#39;a, String, Array1&amp;lt;T&amp;gt;&amp;gt;: Iterator
{
    pub data: Iter&amp;lt;&#39;a, String, Array1&amp;lt;T&amp;gt;&amp;gt;,
    pub other: Vec&amp;lt;String&amp;gt;,
    pub axis: UtahAxis,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Further explorations into the map implementation are needed to see if it realizes performance benefits over the reference-local one.&lt;/p&gt;

&lt;h4 id=&quot;better-error-handling-with-compile-time-dimension-checking&quot;&gt;Better Error handling with compile time dimension checking&lt;/h4&gt;

&lt;p&gt;How do we effectively prevent user errors during data transformation &lt;em&gt;at compile time&lt;/em&gt;?&lt;/p&gt;

&lt;p&gt;So far, the only error handling is in the &lt;code class=&quot;highlighter-rouge&quot;&gt;new()&lt;/code&gt; function, where we check whether the dimensions of the axis labels match that of the underlying data. This actually handles a ton of common errors, like selecting or removing a column that doesn’t exist. But while it does panic in the right situations, the errors are not that useful in figuring out what the actual mistake was:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;IndexShapeMismatch(exp: String , act: String) {
  display(&quot;index shape mismatch. Expected length: {}, Actual length: {}&quot;,  exp, act)
}

ColumnShapeMismatch(exp: String , act: String) {
  display(&quot;column shape mismatch. Expected length: {}, Actual length: {}&quot;,  exp, act)
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Furthermore, the errors are only caught at runtime.&lt;/p&gt;

&lt;p&gt;One thing I’ve been thinking about is compile-time dimension checking with the &lt;a href=&quot;https://github.com/paholg/typenum&quot;&gt;typenum&lt;/a&gt; and &lt;a href=&quot;https://github.com/fizyk20/generic-array&quot;&gt;genericarray&lt;/a&gt; crates, which provide compile-time numeric operations and array dimensions, respectively.&lt;/p&gt;

&lt;p&gt;Using these crates, the dimensions of the inner data and axis labels could be embedded in trait bounds:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub struct DataFrame&amp;lt;T, N, M, O, P&amp;gt;
    where T: UtahNum
          M: ArrayLength&amp;lt;String&amp;gt; + Same&amp;lt;P&amp;gt;,
          P: ArrayLength&amp;lt;T&amp;gt; + Same&amp;lt;M&amp;gt;,
          N: ArrayLength&amp;lt;String&amp;gt; + Same&amp;lt;O&amp;gt;,
          O: ArrayLength&amp;lt;T&amp;gt; + Same&amp;lt;N&amp;gt;,
{
    pub columns: GenericArray&amp;lt;String, M&amp;gt;,
    pub data: GenericArray&amp;lt;GenericArray&amp;lt;T,O&amp;gt;, P&amp;gt;,
    pub index: GenericArray&amp;lt;String, N&amp;gt;,
    phantom_0: PhantomData&amp;lt;&amp;lt;N as Same&amp;lt;O&amp;gt;&amp;gt;::Output&amp;gt;,
    phantom_1: PhantomData&amp;lt;&amp;lt;M as Same&amp;lt;P&amp;gt;&amp;gt;::Output&amp;gt;,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The trait bounds imply that a combinator chain will not compile if the length of the index &lt;code class=&quot;highlighter-rouge&quot;&gt;M&lt;/code&gt; and columns &lt;code class=&quot;highlighter-rouge&quot;&gt;N&lt;/code&gt; don’t match the dimensions of the underlying data.&lt;/p&gt;

&lt;h4 id=&quot;streaming-dataframes&quot;&gt;Streaming DataFrames&lt;/h4&gt;

&lt;p&gt;In reality, the current implementation is an imperfect workaround of what I &lt;em&gt;really&lt;/em&gt; want the dataframe and its combinators to be. Right now, the data owner (&lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt;) is separated from the iterator (&lt;code class=&quot;highlighter-rouge&quot;&gt;DataFrameIterator&lt;/code&gt;) and the combinators.&lt;/p&gt;

&lt;p&gt;I would like the dataframe to be an iterator over some data held in disk, and each combinator borrowed values from a buffer maintained by the dataframe.  Then the real power of the iterator adapter design is realized: we can work with datasets that may not fit into memory.&lt;/p&gt;

&lt;p&gt;What I’m essentially talking about are &lt;em&gt;streaming iterators&lt;/em&gt;, which has been discussed at length &lt;a href=&quot;https://users.rust-lang.org/t/returning-borrowed-values-from-an-iterator/1096&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://github.com/emk/rust-streaming&quot;&gt;here&lt;/a&gt;. There’s another &lt;a href=&quot;https://github.com/sfackler/streaming-iterator&quot;&gt;interesting crate&lt;/a&gt; around this effort too. It’s an exciting concept.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I’ve introduced a new Rust crate for handling complex data transformations with two dimensional iterator adapters. This crate, while extremely nascent, has shown a few strengths so far:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Functional chaining of combinators makes code easy to understand.&lt;/li&gt;
  &lt;li&gt;Iterator adapter design makes the code extremely repeatable and easy to extend to new domains.&lt;/li&gt;
  &lt;li&gt;We get all the benefits of working with Rust’s iterators, which are fast, safe, and lazy.&lt;/li&gt;
  &lt;li&gt;There’s a lot of interesting future work on better mixed type support, compile time numbers, and streaming.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That’s all from me – happy holidays!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The PlayRust Classifier</title>
   <link href="https://suchin.co/2016/09/13/The-PlayRust-Classifier/"/>
   <updated>2016-09-13T00:00:00-07:00</updated>
   <id>https://suchin.co/2016/09/13/The-PlayRust-Classifier</id>
   <content type="html">&lt;p&gt;&lt;em&gt;For those who weren’t able to attend &lt;a href=&quot;http://rustconf.com/&quot;&gt;RustConf 2016&lt;/a&gt;, I thought I’d provide a synopsis of my and /u/staticassert’s talk. I’ve only focused on a subset of talking points below; for the full talk, check out the upcoming video when it’s posted.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;technical-debt-in-data-science&quot;&gt;Technical Debt in Data Science&lt;/h2&gt;

&lt;p&gt;Our RustConf talk, entitled &lt;em&gt;&lt;a href=&quot;https://slides.com/suchingururangan/playrustclassifier&quot;&gt;The PlayRust Classifier&lt;/a&gt;&lt;/em&gt;, was essentially about how to reduce technical debt. It’s something that most software engineers experience regularly – the lack of documentation, unhandled errors, costly scaling, etc. However, technical debt in  machine learning compounds quickly due to unique challenges in the space.&lt;/p&gt;

&lt;p&gt;Most data science teams face the basic problem of moving between research and production-level machine learning. These two types of data science have very different motivations and goals. Research data science is usually one-off and includes a lot of proof-of-concept work, while production-level machine learning may run in the cloud or on a low-memory device, and has the same engineering constraints as any other software product. Most technical debt is accrued in the transition between these phases, especially during feature engineering.&lt;/p&gt;

&lt;div style=&quot;margin-left:175px&quot;&gt;
  &lt;img src=&quot;http://pegasos1.github.io/public/20160913/datapic.jpg&quot; width=&quot;400&quot; height=&quot;400&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The unfortunate reality is that data often sucks in most applicable domains of machine learning.   This means that data scientists spent 99% of their time doing feature engineering – munging through data, building and cleaning features – and only a minority of their time working with machine learning algorithms.&lt;/p&gt;

&lt;p&gt;Tech debt during feature engineering comes in many flavors, as outlined by &lt;em&gt;&lt;a href=&quot;http://research.google.com/pubs/pub43146.html&quot;&gt;Machine Learning: The High Interest Credit Card of Technical Debt (2014)&lt;/a&gt;&lt;/em&gt;, a crucial motivator of our talk:&lt;/p&gt;

&lt;p&gt;1) &lt;strong&gt;Siloed Teams&lt;/strong&gt;: Data scientists and software engineers are usually considered distinct teams. This means that POC research code may not be held up to common engineering standards, and that handoff to production may involve a lot of reimplementation. Furthermore, siloed teams can make ML models more esoteric to those who are tasked with making them production-ready.&lt;/p&gt;

&lt;p&gt;2) &lt;strong&gt;Pipeline Jungles&lt;/strong&gt;: Complex transformations of data to get it into an ML-friendly format means that the related code can be extremely hard to reason about, and thus difficult to move into production. Extraneous, messy supporting code can leak into your codebase, especially in dynamic languages that give you more freedom over the way you represent and manipulate data. Pipeline jungles can prevent errors from bubbling up, making it very difficult to trace where things are breaking.&lt;/p&gt;

&lt;p&gt;3) &lt;strong&gt;Unscalable Experiments&lt;/strong&gt;: Code handed off to engineers may be not only monolithic and hard to reason about, but also difficult to scale. Writing code that is difficult to parallelize may lead to costly horizontal scaling in the cloud.&lt;/p&gt;

&lt;p&gt;The long story short is that machine learning services are not only dependent on the quality of machine learning models, but also the quality of feature engineering and data ingestion. This realization prompted us to look for tools that would help us become more confident that feature engineering pipelines are reliable and robust in a very non-deterministic domain.&lt;/p&gt;

&lt;h2 id=&quot;the-rplayrust-classifier&quot;&gt;The /r/playrust classifier&lt;/h2&gt;

&lt;p&gt;How can Rust help us pay off technical debt in machine learning during the feature engineering stage? To explore the strengths of Rust in this area, my co-speaker and I built a classifier to solve a well-known problem for the Rust reddit community.&lt;/p&gt;

&lt;p&gt;From time to time, someone mistakenly publishes a post in the &lt;em&gt;&lt;a href=&quot;http://reddit.com/r/rust&quot;&gt;/r/rust&lt;/a&gt;&lt;/em&gt; subreddit that was intended for the &lt;em&gt;&lt;a href=&quot;http://reddit.com/r/playrust&quot;&gt;/r/playrust&lt;/a&gt;&lt;/em&gt; subreddit, a community for a popular video game &lt;em&gt;Rust&lt;/em&gt;. We built a classifier to detect these mistakenly published posts.&lt;/p&gt;

&lt;div style=&quot;text-align:center&quot;&gt;
  &lt;img src=&quot;http://pegasos1.github.io/public/20160913/playrust.png&quot; width=&quot;780&quot; height=&quot;400&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;This toy problem was an optimal medium to explore Rust data science, because we were gifted with naturally labeled training data: posts collected from both subreddits. This let us focus on the implementation details.&lt;/p&gt;

&lt;h3 id=&quot;the-model&quot;&gt;The Model&lt;/h3&gt;

&lt;p&gt;Before digging into Rust-specific features of the pipeline we built, let’s quickly look at the resulting model and its accuracy.&lt;/p&gt;

&lt;p&gt;We gathered thousands of reddit posts and looked at a number of features to describe their respective subreddits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Author popularity&lt;/li&gt;
  &lt;li&gt;Upvotes&lt;/li&gt;
  &lt;li&gt;Downvotes&lt;/li&gt;
  &lt;li&gt;Post length&lt;/li&gt;
  &lt;li&gt;Word frequency&lt;/li&gt;
  &lt;li&gt;Symbol frequency&lt;/li&gt;
  &lt;li&gt;Regex matches on Rust code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We then trained a Random Forest with the crate &lt;em&gt;rustlearn&lt;/em&gt; to perform the predictions.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;We achieved good accuracy in our model. The model had a &amp;gt;98% AUC in prediction, as seen below.&lt;/p&gt;

&lt;div style=&quot;margin-left:100px&quot;&gt;
  &lt;img src=&quot;http://pegasos1.github.io/public/20160913/roccurve.png&quot; width=&quot;550&quot; height=&quot;400&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The model was primarily driven by the frequencies of words related to the &lt;em&gt;/r/rust&lt;/em&gt; subreddit. Notice the word “amp”, ie “&amp;amp;”. Haha.&lt;/p&gt;

&lt;div style=&quot;margin-left:100px&quot;&gt;
  &lt;img src=&quot;http://pegasos1.github.io/public/20160913/featimps.png&quot; width=&quot;580&quot; height=&quot;400&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The model outputs a score between 0 and 1 that represents the likelihood that the post in question is part of the &lt;em&gt;/r/rust&lt;/em&gt; subreddit. Some example outputs are below. Notice the third post, with the slightly confusing title, is also slightly confusing to the model.&lt;/p&gt;

&lt;div style=&quot;margin-left:50px&quot;&gt;
  &lt;img src=&quot;http://pegasos1.github.io/public/20160913/examples.png&quot; width=&quot;700&quot; height=&quot;400&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;rust-advantages&quot;&gt;Rust advantages&lt;/h2&gt;

&lt;p&gt;So what was our experience using Rust to build this model end-to-end? Did Rust showcase strengths in reducing technical debt?&lt;/p&gt;

&lt;h3 id=&quot;upfront-error-handling&quot;&gt;Upfront error handling&lt;/h3&gt;

&lt;p&gt;A powerful aspect of the Rust language is the idea that developers must handle potential errors upfront.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_reddit_post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RawPostData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.client&lt;/span&gt;
                     &lt;span class=&quot;nf&quot;&gt;.get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                     &lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                     &lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

   &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extract_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                  &lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In the above code, we send a &lt;code class=&quot;highlighter-rouge&quot;&gt;GET&lt;/code&gt; request to a url, and extract data from it. You can see that you &lt;em&gt;must&lt;/em&gt; handle the potential errors that could surface from each of these operations. For example, the network could go down, or data extraction may fail for some reason. We easily handle potential errors with an &lt;em&gt;unwrap()&lt;/em&gt; method, in which we assert that we are sure that this method won’t fail on us. This may be something you see in POC research code. We don’t really need anything fancy here.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_reddit_post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RawPostData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nd&quot;&gt;try!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.client&lt;/span&gt;
                            &lt;span class=&quot;nf&quot;&gt;.get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                            &lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                            &lt;span class=&quot;nf&quot;&gt;.chain_err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(||&lt;/span&gt;
                                &lt;span class=&quot;nd&quot;&gt;format!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Failed to GET {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;


     &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nd&quot;&gt;try!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;extract_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                    &lt;span class=&quot;nf&quot;&gt;.chain_err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(||&lt;/span&gt;
                          &lt;span class=&quot;nd&quot;&gt;format!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Failed to parse data {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;
     &lt;span class=&quot;nf&quot;&gt;Ok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;But in production, we definitely want to handle any potential errors in some meaningful way. We can do this with the &lt;code class=&quot;highlighter-rouge&quot;&gt;try!&lt;/code&gt; macro.&lt;/p&gt;

&lt;p&gt;This approach to handling errors is different from the unchecked exceptions paradigm in languages like Python or Java. Unlike try/except, &lt;code class=&quot;highlighter-rouge&quot;&gt;try!&lt;/code&gt; is precise. In the former paradigm, you tend to wrap larger codeblocks with try/except, when in reality only parts of the code may fail.&lt;/p&gt;

&lt;p&gt;Furthermore, potential errors are  baked into the output type of the function (the &lt;code class=&quot;highlighter-rouge&quot;&gt;Result&lt;/code&gt; type). This means that proper error handling can occur &lt;em&gt;without knowledge of function implementation&lt;/em&gt;. On the developer’s side, it’s easy to move from research code to production, just &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl+F&lt;/code&gt; the &lt;code class=&quot;highlighter-rouge&quot;&gt;unwraps&lt;/code&gt;, and handle them with &lt;code class=&quot;highlighter-rouge&quot;&gt;try!&lt;/code&gt; macros.&lt;/p&gt;

&lt;h3 id=&quot;typed-approach-to-dataframes&quot;&gt;Typed approach to Dataframes&lt;/h3&gt;

&lt;p&gt;Dataframes are a tabular data format for many languages like Python, R, and Julia. Dataframes are ergonomic, but can lead to technical debt, by allowing things like mixed types per column. This could lead to bugs in which unexpected values crop up where they’re not supposed to – a big headache to trace in large datasets.&lt;/p&gt;

&lt;p&gt;In static languages like Rust, we do care about types associated with our data. For the &lt;em&gt;/r/playrust&lt;/em&gt; classifier, we stored raw data collected about the subreddits in a struct called &lt;code class=&quot;highlighter-rouge&quot;&gt;RawPostData&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RawPostData&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;is_self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;author_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;downvotes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;u64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;upvotes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;u64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;u64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;edited&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;selftext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;subreddit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And extracted features were stored in a struct called &lt;code class=&quot;highlighter-rouge&quot;&gt;ProcessedPostFeatures&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProcessedPostFeatures&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;is_self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;author_popularity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;downs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;ups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;post_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;word_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;symbol_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;regex_matches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;f32&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RawPostData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_raw_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_author_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Each field of the struct was equivalent to a dataframe column, and each index of the field was equivalent to a dataframe row. This typed approach gave us confidence that we did not populate unexpected values in our dataframe for a particular column. We could apply transformations in our data in the normal way we map over iterators.&lt;/p&gt;

&lt;h3 id=&quot;parallelization&quot;&gt;Parallelization&lt;/h3&gt;

&lt;p&gt;Furthermore, this structure to dataframes allowed us to easily parallelize operations with crates like &lt;em&gt;rayon&lt;/em&gt;. We just change &lt;code class=&quot;highlighter-rouge&quot;&gt;iter&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;par_iter&lt;/code&gt; in the code above, and we’re golden.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;extern&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;crate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rayon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rayon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;prelude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RawPostFeatures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_raw_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;processed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;with_capacity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.par_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_author_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.collect_into&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;processed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;other-advantages&quot;&gt;Other advantages&lt;/h3&gt;

&lt;p&gt;There are many other very useful aspects of Rust for the data science pipeline, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Predictable performance during scaling&lt;/li&gt;
  &lt;li&gt;Cargo testing, benchmarking, and docs help devs follow good coding practices&lt;/li&gt;
  &lt;li&gt;Trait composition/generics limit the need for messy glue code&lt;/li&gt;
  &lt;li&gt;Many benchmarks (like &lt;a href=&quot;http://www.suchin.co/2016/04/25/Matrix-Multiplication-In-Rust-Pt-1/&quot;&gt;this&lt;/a&gt; one) suggest Rust’s strong performance in numerics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rust-disadvantages&quot;&gt;Rust disadvantages&lt;/h2&gt;

&lt;p&gt;While using Rust was generally a pleasant experience for this project, there were some areas in which the language fell short.&lt;/p&gt;

&lt;h3 id=&quot;fragmented-ml-ecosystem&quot;&gt;Fragmented ML ecosystem&lt;/h3&gt;

&lt;p&gt;The reality is that the current machine learning community is sparse. We found that while there are 60+ crates on crates.io associated with machine learning or linear algebra, many of these libraries provide similar functionality with different APIs. For example, most machine learning tools have custom matrix implementations. This limits the interoperability of crates that makes a language like Python, which builds most of its numeric libraries around the numpy array, very attractive for data science.&lt;/p&gt;

&lt;h3 id=&quot;data-exploration-difficult-in-a-static-language&quot;&gt;Data exploration difficult in a static language&lt;/h3&gt;

&lt;p&gt;Dynamic languages like Python and R dominate data investigation, and with good reason. A REPL/interpreter lends itself very well to exploration, because you have instant feedback to tweaks in your code – you don’t need to re-compile to see effects. Furthermore, during the data investigation stage, performance is not that important, so we can get away with ignoring language level details that may slow us down while exploring. Last, Python and R are laden with libraries around graphing and visualization, which is totally non-existent in Rust. Most mature machine learning systems are hybrids of languages and tools specialized for specific tasks, and we envision Python and R still dominating this space.&lt;/p&gt;

&lt;h2 id=&quot;vision-for-rust-ml&quot;&gt;Vision for Rust ML&lt;/h2&gt;

&lt;p&gt;We have shown that Rust language features help reduce many technical debt issues that arise in making production level data science systems. We hope that Rust is promoted to improve feature engineering systems. We also hope that implementations of data science tooling become standardized to facilitate interoperability. Finally, we believe that effective domain applications of a language are primarily driven by the community that forms around it. We should start sharing ideas and building a collective metric for success in Rust machine learning and numerics.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Have I Been Pwned? with Python</title>
   <link href="https://suchin.co/2016/06/05/Introducing-The-Have-I-Been-Pwned-Python-API/"/>
   <updated>2016-06-05T00:00:00-07:00</updated>
   <id>https://suchin.co/2016/06/05/Introducing-The-Have-I-Been-Pwned?-Python-API</id>
   <content type="html">&lt;p&gt;Massive data breaches are becoming more and more common these days. How can you tell whether you’re safe?&lt;/p&gt;

&lt;p&gt;The recently launched &lt;a href=&quot;https://haveibeenpwned.com&quot;&gt;Have I Been Pwned&lt;/a&gt; (HIBP) service can help. HIBP is a free resource to quickly assess if an account or domain has been compromised in a data breach. The project helps victims become aware of these security situations as fast as possible, and highlights the severity of Internet-wide attacks.&lt;/p&gt;

&lt;p&gt;To make HIBP accessible to developers, I built a Python wrapper around its API: &lt;a href=&quot;http://github.com/pegasos1/haveibeenpwned&quot;&gt;hibp&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;With this library you can access a number of HIBP services from Python, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;breaches on a particular domain (linkedin.com, ashleymadison.com)&lt;/li&gt;
  &lt;li&gt;breaches on a user account or email (pegasos1, example@gmail.com)&lt;/li&gt;
  &lt;li&gt;all historical breaches of a particular name (adobe, linkedin)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each service request object contains a response attribute that holds the raw data in JSON format. To perform a query, just setup a service request object, and then execute it:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;hibp&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_account_breaches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pegasos1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You can see a full example script of how to use the API &lt;a href=&quot;https://github.com/pegasos1/haveibeenpwned/blob/master/hibp/example.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here’s some example data we get back when we query for data breaches on &lt;code class=&quot;highlighter-rouge&quot;&gt;adobe.com&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_domain_breaches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;adobe.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dumps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sort_keys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;AddedDate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2013-12-04T00:00:00Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;BreachDate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2013-10-04&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;DataClasses&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Email addresses&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Password hints&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Passwords&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Usernames&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Description&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;In October 2013, 153 million Adobe accounts were breached...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Domain&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;adobe.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;IsActive&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;IsRetired&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;IsSensitive&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;IsVerified&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;LogoType&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;svg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Adobe&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;PwnCount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;152445165&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Adobe&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Cool, huh? We can see when the breach occurred, the various types of data that were leaked,  a brief description of the breach, whether it’s still active and verified, and how many accounts were affected. You can check &lt;a href=&quot;https://haveibeenpwned.com/API/v2#BreachModel&quot;&gt;here&lt;/a&gt; for a full description of all the data fields.&lt;/p&gt;

&lt;p&gt;If you want to query on multiple accounts or domains at once, you can use the &lt;code class=&quot;highlighter-rouge&quot;&gt;AsyncHIBP&lt;/code&gt; object, which can perform queries concurrently via &lt;a href=&quot;http://www.gevent.org/&quot;&gt;gevent&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;hibp&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncHIBP&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;adobe&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;ashleymadison&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;myspace&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;breaches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_breach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;async_reqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncHIBP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;breaches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;async_req&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;async_req&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;async_reqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You can also perform lazy evaluations on multiple accounts or domains with the &lt;code class=&quot;highlighter-rouge&quot;&gt;imap&lt;/code&gt; method. This will return a generator on request objects, which could be more memory efficient if you’re working with a larger list of queries.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domains&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;twitter.com&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;facebook.com&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;myspace.com&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;breaches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_domain_breaches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;async_reqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncHIBP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;breaches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;async_reqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Concurrent queries are much faster than serial ones:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# random set of query parameters&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;adobe&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;ashleymadison&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;linkedin&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;myspace&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;accounts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ssgrn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;pegasos1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;barackobama&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;domains&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;twitter.com&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;facebook.com&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;github.com&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;adobe.com&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# setup HIBP objects for request executions&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_breach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; \
       &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_account_breaches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accounts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; \
       &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HIBP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_domain_breaches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### SERIAL&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elapsed_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;### 110.9 SECONDS&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;serial impl took &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%.2&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f seconds&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elapsed_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### CONCURRENT&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;async_reqs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncHIBP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elapsed_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;### 10.01 SECONDS&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;concurrent impl took &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%.2&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f seconds&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elapsed_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;There’s still work to do here. For example, I should add some functionality to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Convert the JSON data to a pandas dataframe or CSV&lt;/li&gt;
  &lt;li&gt;Provide some simple helper functions to get users going (e.g. methods like &lt;code class=&quot;highlighter-rouge&quot;&gt;list_all_breaches()&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;breach.number_pwned()&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I think this project will be useful for developers who want to build applications that programmatically assess whether accounts or sites are compromised. These types of products could drive faster remediation when large-scale security incidents occur. Also this project will be useful for applications that aim to analyze bulk, historical breach data for security research.&lt;/p&gt;

&lt;p&gt;As always, I welcome contributors and feedback!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Introducing Cargo Profiler</title>
   <link href="https://suchin.co/2016/05/11/Introducing-Cargo-Profiler/"/>
   <updated>2016-05-11T00:00:00-07:00</updated>
   <id>https://suchin.co/2016/05/11/Introducing-Cargo-Profiler</id>
   <content type="html">&lt;p&gt;Profiling tools can help you write fast and efficient code. However, whether you use perf, oprofile, or valgrind, you have to exit the Rust ecosystem to profile your applications. This has always been a little cumbersome to me, so I built a cargo subcommand to perform the job: &lt;a href=&quot;https://github.com/pegasos1/cargo-profiler&quot;&gt;cargo-profiler&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cargo-profiler interfaces with Linux-based profiling tools to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Profile your applications&lt;/li&gt;
  &lt;li&gt;Parse profiler output into structs for further analysis&lt;/li&gt;
  &lt;li&gt;Display information to you in the most user-friendly way possible.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, instead of this gross cachegrind output:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;valgrind --tool=cachegrind $BINARY &amp;amp;&amp;amp; cg_annotate $OUT_FILE&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160511/cachegrind_pic.png&quot; width=&quot;900&quot; height=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You get this prettier cachegrind output:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cargo profiler cachegrind --bin=$BINARY -n 10&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160511/cargoprofiler.png&quot; alt=&quot;Cargo profiler&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since cargo-profiler parses performance statistics into machine-readable, structured objects, we can do a lot more with the data, even in a programmatic way.&lt;/p&gt;

&lt;p&gt;This project is in its infancy, and here are some current ideas on the roadmap:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Comparisons between profiling runs&lt;/li&gt;
  &lt;li&gt;Creating macros that conditionally compile a binary with functions you want to profile&lt;/li&gt;
  &lt;li&gt;Getting better context around expensive functions in your library (location, types, etc.)&lt;/li&gt;
  &lt;li&gt;Building support for more profiling tools&lt;/li&gt;
  &lt;li&gt;Creating alternate consumptions of profiling data (e.g. visualizations)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, cargo-profiler is a simple and lightweight app that merely serves as an interface to existing tools. There’s a whole world beyond this project that involves totally new and native Rust profiling workflows. These workflows could be really powerful and address some caveats to profiling Rust programs today. For example, compiler optimizations like inlining  render some functions at the code-level mangled or lost to valgrind. Perhaps native profiling at the MIR or LLVM level can solve this issue.&lt;/p&gt;

&lt;p&gt;Native Rust profiling would definitely require major work, so in the meantime, leveraging existing tools seems like a good first step! I hope this tool is useful to you developers.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Matrix Multiplication in Rust (Part 1)</title>
   <link href="https://suchin.co/2016/04/25/Matrix-Multiplication-In-Rust-Pt-1/"/>
   <updated>2016-04-25T00:00:00-07:00</updated>
   <id>https://suchin.co/2016/04/25/Matrix-Multiplication-In-Rust-Pt-1</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Thanks to staticassert for feedback, and bluss for conversations. Source code can be found &lt;a href=&quot;http://github.com/pegasos1/rsmat&quot;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This post is the first of a series.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Basic Linear Algebra Subprograms (BLAS) are the routines that underpin most high-level computational libraries today. Written in C and FORTRAN, they are acutely optimized for speed, and take advantage of special hardware features to achieve unparalleled performance in matrix computations.&lt;/p&gt;

&lt;p&gt;It’s an early time for Rust, but we’re already seeing strides (pun intended) in the numeric computing space.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; I was recently inspired to investigate how to make fast matrix computations in Rust, using ndarray-rblas compiled with OpenBLAS&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; as the target benchmark. This blog series is a documentation of those explorations.&lt;/p&gt;

&lt;p&gt;In this post, I’ll detail, on a high-level, the process of making fast matrix computations.&lt;/p&gt;

&lt;p&gt;The analyses in this post will involve the use of rust-ndarray&lt;sup id=&quot;fnref:1:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; for matrix computations. All the crate-specific methods I use are documented &lt;a href=&quot;http://bluss.github.io/rust-ndarray/master/ndarray/index.html&quot;&gt;here&lt;/a&gt;. I’m on a basic Linux laptop: 4-core, i5 CPU with 8 GB RAM.&lt;/p&gt;

&lt;h2 id=&quot;naive-dot-product&quot;&gt;Naive dot product&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;A fundamental operation in numeric computing is the dot product between matrices &lt;script type=&quot;math/tex&quot;&gt;A = [a_1 ,..., a_n]&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;B = [b_1,...,b_n]&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;dot(A,B) = a_1b_1 + a_2b_2 + ... + a_nb_n&lt;/script&gt;

&lt;p&gt;It’s a simple operation and a great way to dig into performance optimization. So let’s start here!&lt;/p&gt;

&lt;p&gt;We’ll use the following type aliases:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub type VectorView&amp;lt;&#39;a, A&amp;gt; = ArrayView&amp;lt;&#39;a, A, Ix&amp;gt;;
pub type MatView&amp;lt;&#39;a, A&amp;gt; = ArrayView&amp;lt;&#39;a, A, (Ix, Ix)&amp;gt;;
pub type MatViewMut&amp;lt;&#39;a, A&amp;gt; = ArrayViewMut&amp;lt;&#39;a, A, (Ix, Ix)&amp;gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;ArrayView(Mut)s are (mutable) references to a matrix, or part of it. They’re good objects to use if you want to  work with modular subviews of a matrix.&lt;/p&gt;

&lt;p&gt;We begin with a naive implementation of the dot product, in which we fold a multiplicative sum of values in vectors &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub fn vector_dot(a : VectorView&amp;lt;f64&amp;gt;,b:  VectorView&amp;lt;f64&amp;gt;) -&amp;gt; f64 {
        (0..a.len()).fold(0.0, |x, y| x + a.get(y).unwrap() * b.get(y).unwrap() )
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We then define a matrix dot product like so:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub fn matrix_dot( a : &amp;amp;MatView&amp;lt;f64&amp;gt;, b: &amp;amp;MatView&amp;lt;f64&amp;gt;, c : &amp;amp;mut MatViewMut&amp;lt;f64&amp;gt;){
    let ((m,k1),(k2,n)) = (a.dim(),b.dim());
    assert_eq!(k1,k2);
    for ix in 0..m{
        for jx in 0..n{
            let a_row = a.row(ix);
            let b_col = b.column(jx);
            let mut value = c.get((ix,jx)).unwrap();
            *value += vector_dot(a_row, b_col);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In the code above, we first check whether the inner and outer dimensions of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; (respectively) are the same. Then we loop through the matrices’ rows and columns, applying our &lt;code class=&quot;highlighter-rouge&quot;&gt;vector_dot&lt;/code&gt; function and updating a separate matrix &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; with the corresponding output.&lt;/p&gt;

&lt;p&gt;Here are the benchmarks, compared to OpenBLAS, on multiplying &lt;script type=&quot;math/tex&quot;&gt;128 \times 100&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;100 \times 128&lt;/script&gt; matrices:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test bench_dot_dumb        ... bench:   2,843,823 ns/iter (+/- 110,881)

test bench_dot_openblas    ... bench:   201,170 ns/iter (+/- 18,666)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Wow, that sucks. We’re at least 10x slower than OpenBLAS. But the above implementation is called naive for a reason; we can do a lot better.&lt;/p&gt;

&lt;h2 id=&quot;unsafe-indexing&quot;&gt;Unsafe indexing&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;get()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;get_mut()&lt;/code&gt;  checks matrix dimensions before returning the indexed value. This makes for safe code, since ndarray will throw an error if the supplied index falls outside of the matrix dimensions (hence the &lt;code class=&quot;highlighter-rouge&quot;&gt;unwrap&lt;/code&gt;). However, index checking wastes time, and we’re trying to make things as fast as possible.&lt;/p&gt;

&lt;p&gt;The first thing we could do is index the matrix &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; with unsafe methods &lt;code class=&quot;highlighter-rouge&quot;&gt;uget()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;uget_mut()&lt;/code&gt;. These don’t check the bounds of the matrix when indexing, and will save us time.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub fn vector_dot_unsafe(a : VectorView&amp;lt;f64&amp;gt;,b:  VectorView&amp;lt;f64&amp;gt;) -&amp;gt; f64 {
    unsafe{
        (0..a.len()).fold(0.0, |x, y| x + a.uget(y) * b.uget(y))
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub fn matrix_dot_unsafe( a : &amp;amp;MatView&amp;lt;f64&amp;gt;, b: &amp;amp;MatView&amp;lt;f64&amp;gt;,
                        c : &amp;amp;mut MatViewMut&amp;lt;f64&amp;gt;){
    let ((m,k1),(k2,n)) = (a.dim(),b.dim());
    assert_eq!(k1,k2);
    for ix in 0..m{
        for jx in 0..n{
            let a_row = a.row(ix);
            let b_col = b.column(jx);
            unsafe{
                let mut value = c.uget_mut((ix,jx));
                *value += vector_dot_unsafe( a_row, b_col);
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We achieve about a 2x speedup with this change.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test bench_dot_dumb        ... bench:   1,518,253 ns/iter (+/- 24,523)

test bench_dot_openblas    ... bench:   201,170 ns/iter (+/- 18,666)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;improve-matrix-multiplication&quot;&gt;Improve matrix multiplication&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;The second thing we can do is employ some black magic to improve our matrix multiplication.&lt;/p&gt;

&lt;p&gt;The matrixmultiply crate&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; computes the dot product by decomposing the full computation into a layered set of mini subproblems that can be efficiently packed into the cache. For an in-depth review of the algorithm and its implementation, I’ll refer you to another post on the subject &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;By replacing the naive dot product with this smarter version, natively supported in ndarray via the method &lt;code class=&quot;highlighter-rouge&quot;&gt;dot&lt;/code&gt;, we achieve significant speed up:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub fn matrix_dot( left : &amp;amp;MatView&amp;lt;f64&amp;gt;, right: &amp;amp;MatView&amp;lt;f64&amp;gt;,
                  init : &amp;amp;mut MatViewMut&amp;lt;f64&amp;gt;){
    let dot_prod = left.dot(right);
    for ix in 0..m{
        for jx in 0..n{
            unsafe{
            let mut value = init.uget_mut((ix,jx));
            let res = dot_prod.uget_mut((ix,jx));
            *value += res;
          }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test bench_dot_matrixmultiply      ... bench:     370,281 ns/iter (+/- 14,179)

test bench_dot_openblas        ... bench:   201,170 ns/iter (+/- 18,666)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Nice! We’ve increased the speed almost 4x. Now let’s try to get our algorithm even closer to OpenBLAS performance.&lt;/p&gt;

&lt;h2 id=&quot;avoid-explicit-bounds-checking&quot;&gt;Avoid explicit bounds checking&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;Let’s revisit the indexing issue in the loop. We gained some significant speedups by making our code unsafe, but this isn’t ideal. Let’s see if we can get speed &lt;em&gt;and&lt;/em&gt; safety.&lt;/p&gt;

&lt;p&gt;The trick here is that matrix elements in ndarray implement &lt;code class=&quot;highlighter-rouge&quot;&gt;Iterator&lt;/code&gt;, and &lt;em&gt;iteration naturally lends itself to bounds checking elimination optimization&lt;/em&gt;. It’s implicitly safe to iterate over the matrix. We can assign the values of our dot product to &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; safely without having to make sure we’re within the matrix dimensions.&lt;/p&gt;

&lt;p&gt;With this in mind, we can simplify the loop to a one-liner that involves the iterator method &lt;code class=&quot;highlighter-rouge&quot;&gt;zip&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;c.zip_mut_with(&amp;amp;dot_prod, |x, y| *x = *y)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This results in a smarter, faster matrix multiplication below:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub fn matrix_dot_safe(a: &amp;amp;MatView&amp;lt;f64&amp;gt;, b: &amp;amp;MatView&amp;lt;f64&amp;gt;,
  c: &amp;amp;mut MatViewMut&amp;lt;f64&amp;gt;) {
    let ((_,k1),(k2,_)) = (a.dim(),b.dim());
    assert_eq!(k1,k2);
    let dot_prod = a.dot(b);
    c.zip_mut_with(&amp;amp;dot_prod, |x, y| *x = *y)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Because ndarray matrices implement &lt;code class=&quot;highlighter-rouge&quot;&gt;Iterator&lt;/code&gt;, we can use array methods to achieve safety without sacrificing speed. And we get simplicity for free.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;test &lt;/span&gt;bench_dot_safe            ... bench:     346,677 ns/iter &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;+/- 13,246&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;test &lt;/span&gt;bench_dot_openblas        ... bench:   201,170 ns/iter &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;+/- 18,666&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Why are we still assigning the dot product of  &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt;? Well, we’re just thinking one step ahead - towards parallelization.&lt;/p&gt;

&lt;h2 id=&quot;parallelization&quot;&gt;Parallelization&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;Another optimization we can make involves multi-threading. Rust is great for writing concurrent programs because its memory management and type system free the developer from dealing with data races.&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;There are quite a few crates that assist the developer in making multi-threaded applications, but the one I’ll focus on here is Rayon&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;The core of Rayon’s API is a work-stealing thread pool. Worker threads pop tasks from a queue, and additional threads are spawned as needed to “steal” future work from busy threads. The really interesting thing about Rayon is that parallelism is not &lt;em&gt;guaranteed&lt;/em&gt;; instead, it’s dependent on whether idle cores are available. It’s great to release the developer from thinking about when to use concurrency, and let the API handle it. For an explanation on how this works, I’ll refer you to a series of posts here&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Rayon works best with divide-and-conquer algorithms, which happens to be an optimal technique for matrix multiplication.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.catonmat.net/blog/wp-content/uploads/2009/12/matrix-multiplication-blocks.gif&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We call &lt;code class=&quot;highlighter-rouge&quot;&gt;join&lt;/code&gt; on recursively divided matrices, spawning threads to perform multiplication on blocks when we reach some minimum dimension, called &lt;code class=&quot;highlighter-rouge&quot;&gt;BLOCKSIZE&lt;/code&gt;. The next section will detail the effects of the &lt;code class=&quot;highlighter-rouge&quot;&gt;BLOCKSIZE&lt;/code&gt; parameter on performance, but for now we arbitrarily set it to 64.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pub const BLOCKSIZE: usize = 64;

pub fn matrix_dot_rayon(a: &amp;amp;MatView&amp;lt;f64&amp;gt;, b: &amp;amp;MatView&amp;lt;f64&amp;gt;,
                        c: &amp;amp;mut MatViewMut&amp;lt;f64&amp;gt;) {

    let (m, k1) = a.dim();
    let (k2, n) = b.dim();
    assert_eq!(k1, k2);

    if m &amp;lt;= BLOCKSIZE &amp;amp;&amp;amp; n &amp;lt;= BLOCKSIZE {
        matrix_dot_safe(a, b, c);
        return;
    } else if m &amp;gt; BLOCKSIZE {
        let mid = m / 2;
        let (a_0, a_1) = a.split_at(Axis(0), mid);
        let (mut c_0,
            mut c_1) = c.view_mut().split_at(Axis(0), mid);
        rayon::join(|| matrix_dot_rayon(&amp;amp;a_0, b, &amp;amp;mut c_0),
                    || matrix_dot_rayon(&amp;amp;a_1, b, &amp;amp;mut c_1));

    } else if n &amp;gt; BLOCKSIZE {
        let mid = n / 2;
        let (b_0, b_1) = b.split_at(Axis(1), mid);
        let (mut c_0,
            mut c_1) = c.view_mut().split_at(Axis(1), mid);
        rayon::join(|| matrix_dot_rayon(a, &amp;amp;b_0, &amp;amp;mut c_0),
                    || matrix_dot_rayon(a, &amp;amp;b_1, &amp;amp;mut c_1));
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As before, we first make sure dimensions of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; are consistent. Then we enter into the rayon loop. The program recursively divides &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; until it reaches the minimum threshold for blocksize, at which point the spawned thread(s) begin multiplication on the blocks of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; and update the corresponding blocks of &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; accordingly.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test bench_dot_rayon           ... bench:     224,570 ns/iter (+/- 45,483)
test bench_dot_openblas        ... bench:   201,170 ns/iter (+/- 18,666)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It now looks like we’re competitive with OpenBLAS on my machine.&lt;/p&gt;

&lt;h2 id=&quot;rayon-performance-graph&quot;&gt;Rayon Performance Graph&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;I was interested in how Rayon matrix multiplication performance depended on &lt;code class=&quot;highlighter-rouge&quot;&gt;BLOCKSIZE&lt;/code&gt; and the overall dimensions of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;First,  I looked at two &lt;script type=&quot;math/tex&quot;&gt;128 \times 100&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;100 \times 128&lt;/script&gt; matrices. I varied the inner dimension of both matrices in lockstep, and computed benchmarks with/without rayon.&lt;/p&gt;

&lt;p&gt;As you can see, with smaller blocksizes, Rayon does consistently worse than single-threaded multiplication.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160424/fig1.png&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;fun-experiment-on-ec2&quot;&gt;Fun experiment on EC2&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;I was also interested in how the performance of this matrix multiplication program scaled with compute power. I ran the program on Amazon Web Services EC2 – a compute optimized c4.2xlarge instance.&lt;/p&gt;

&lt;p&gt;A c4.2xlarge  instance has 8 cores of “high frequency Intel Xeon E5-2666 v3 (Haswell) processors optimized specifically for EC2”, and 15 GB of RAM.&lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; With high compute power and low extraneous CPU activity, I expected to see far better performance.&lt;/p&gt;

&lt;p&gt;Here are the results of multiplying &lt;script type=&quot;math/tex&quot;&gt;128 \times 100&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;100 \times 128&lt;/script&gt; matrices on that machine.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test bench_dot ... bench: 323,867 ns/iter (+/- 4,005)
test bench_dot_rayon ... bench: 195,585 ns/iter (+/- 15,530)
test bench_dot_openblas ... bench: 91,242 ns/iter (+/- 686)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Rayon’s performance improved quite a bit! But, it gets blown out of the water by OpenBLAS. No competition here.&lt;/p&gt;

&lt;p&gt;We’ll dig deeper into these types of tests on various EC2 instances in the last post of this series.&lt;/p&gt;

&lt;h2 id=&quot;things-to-consider&quot;&gt;Things to consider&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;It’s hard to interpret/generalize the results of concurrent programs because, as I showed above, they’re highly dependent on a variety of parameters, like the size of the data, the number of threads, the power of the CPU, and the cache size. On top of that, Rayon’s &lt;em&gt;potential parallelism&lt;/em&gt; concept, while really useful for development, makes the overall program a  bit of a black box. For example, why exactly does rayon performance degrade with a smaller &lt;code class=&quot;highlighter-rouge&quot;&gt;BLOCKSIZE&lt;/code&gt;? Maybe each computation was so ephemeral on a smaller &lt;code class=&quot;highlighter-rouge&quot;&gt;BLOCKSIZE&lt;/code&gt; that rayon didn’t spawn enough threads. Or perhaps I had a random background process that suddenly limited the amount of threads I could allocate. Or perhaps cache lines are the primary determinant of which &lt;code class=&quot;highlighter-rouge&quot;&gt;BLOCKSIZE&lt;/code&gt; is optimal.&lt;/p&gt;

&lt;p&gt;In the next post of this series, we’ll go under the hood by investigating the CPU and cache to understand &lt;em&gt;why&lt;/em&gt; our code improvements resulted in faster performance, hopefully answering some of these questions and controlling for the many factors that can affect the algorithm’s speed.&lt;/p&gt;

&lt;p&gt;For now, see these results as a showcase of Rayon, as well as an example of how matrix multiplication in Rust can be &lt;em&gt;really&lt;/em&gt; fast and easy to optimize.&lt;/p&gt;

&lt;p&gt;Numeric computing in Rust is exciting. Hope to see more work in this space!&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://github.com/bluss/rust-ndarray&quot;&gt;rust-ndarray&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:1:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://github.com/autumnai/leaf&quot;&gt;leaf&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://github.com/bluss/rust-ndarray/tree/master/ndarray-rblas&quot;&gt;ndarray-rblas&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://crates.io/crates/matrixmultiply&quot;&gt;matrixmultiply&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://bluss.github.io/rust/2016/03/28/a-gemmed-rabbit-hole/#fn:2&quot;&gt;matrixmultiply explanation&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://doc.rust-lang.org/nomicon/send-and-sync.html&quot;&gt;send and sync&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://crates.io/crates/rayon&quot;&gt;rayon&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/&quot;&gt;rayon explanation&lt;/a&gt; &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/ec2/instance-types/&quot;&gt;instance types&lt;/a&gt; &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>The Topology of Malicious Activity on IPv4</title>
   <link href="https://suchin.co/2016/03/23/Topology-Of-Malicious-Activity/"/>
   <updated>2016-03-23T00:00:00-07:00</updated>
   <id>https://suchin.co/2016/03/23/Topology-Of-Malicious-Activity</id>
   <content type="html">&lt;p&gt;At Rapid7, we’re building tools that help us investigate the threat landscape across the Internet. Projects Sonar&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and Heisenberg&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; give us global exposure to common vulnerabilities and patterns in offensive attacks. Our machine learning projects can detect and characterize phishing URLs and SSL certificates. Our threat intelligence repository is growing with datasets that resolve malicious activity to address blocks and autonomous systems.&lt;/p&gt;

&lt;p&gt;We have recently focused our research on how these tools can work together to provide unique insights on the state of the Internet. In this post, we’ll present the beginning of our explorations to identify stable, macro-level attacks trends invisible on the scale of IP addresses.&lt;/p&gt;

&lt;h3 id=&quot;ipv4-topology&quot;&gt;IPv4 Topology&lt;/h3&gt;
&lt;p&gt;First, a quick primer on IPv4, the fourth version of the Internet Protocol. The topology of IPv4 is characterized by three levels of hierarchy, from smallest to largest: IP addresses, subnets, and autonomous systems (ASes). IP addresses on IPv4 are 32-bit sequences that identify hosts or network interfaces. Subnets are groups of IP addresses, and ASes are blocks of subnets managed by public institutions and private enterprises. IPv4 is divided into about 65,000 ASes, at least 30M subnets, and &lt;script type=&quot;math/tex&quot;&gt;2^{32}&lt;/script&gt; IP addresses.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig1.png&quot; alt=&quot;Phishing Activity&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;malicious-ases&quot;&gt;Malicious ASes&lt;/h3&gt;
&lt;p&gt;There has been a great deal of academic and industry focus on identifying malicious activity across
autonomous systems, and for good reasons.&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; Over 50% of “good” Internet traffic comes
from large, ocean-like ASes pushing content from companies like Netflix, Google, Facebook, Apple and Amazon.  However, despite this centralized content, the vastness of the Internet enables those with malicious intent to stake their claim in less friendly waters. In fact, our longitudinal data on phishing activity across IPv4 presented an interesting trend: &lt;em&gt;a small subset of autonomous systems have regularly hosted a disproportionate
amount of malicious activity&lt;/em&gt;. In particular, 200 ASes hosted 70% of phishing activity from 2007 to 2015
(data: cleanmx archives&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;). We wanted to understand what makes some autonomous systems more
likely to host malicious activity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig2.png&quot; alt=&quot;IPv4 fragmentation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ipv4-fragmentation&quot;&gt;IPv4 Fragmentation&lt;/h3&gt;

&lt;p&gt;We gathered historical mappings between IP addresses and ASes from 2007 to 2015 to understand the history of IPv4. The data clearly suggested that IPv4 has been fragmenting. The total number of ASes has grown about 60% in the past decade, and during the same period, there has been a rise in the number of small ASes and a decline in the number of large ones. These results make sense given that the IPV4 address space has been exhausted. This means that growth in IPv4 access requires the reallocation of existing address space into smaller and smaller independent blocks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig3.png&quot; alt=&quot;AS fragmentation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;as-fragmentation&quot;&gt;AS Fragmentation&lt;/h3&gt;

&lt;p&gt;Digging deeper into the Internet’s topological hierarchy, we analyzed the composition, size, and fragmentation of malicious ASes.&lt;/p&gt;

&lt;p&gt;ARIN, one of the primary registrars of ASes, categorizes subnets based on the number of IP addresses they contain.&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; We found that the smallest subnets available made up on average 56 &lt;script type=&quot;math/tex&quot;&gt;\pm&lt;/script&gt; 3.0 percent of a malicious AS.&lt;/p&gt;

&lt;p&gt;Furthermore, we inferred the the size of an AS by calculating its maximum amount of addressable space. Malicious ASes were in the 80-90th percentile in size across IPv4.&lt;/p&gt;

&lt;p&gt;Finally, to compute fragmentation, subnets observed in ASes overtime were organized into trees based on parent-child relationships (Figure 3). We then calculated the ratio of the number of root subnets, which have no parents, to the number of child subnets across the lifetime of the AS. We found that malicious ASes were 10-20% more fragmented than other ASes in IPv4.&lt;/p&gt;

&lt;p&gt;These results suggest that malicious ASes are large and deeply fragmented into small subnets. ARIN fee schedules showed that smaller subnets are significantly less expensive to purchase.&lt;sup id=&quot;fnref:8:1&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; Cheap, small subnets may allow malicious registrars to purchase many IP blocks for traffic redirection or proxy servers, so they can better float under the radar.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig5.png&quot; alt=&quot;topologies&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Our research presents the following results:&lt;/p&gt;

&lt;p&gt;1) A small subset of ASes host a disproportionate amount of malicious activity.&lt;/p&gt;

&lt;p&gt;2) Smaller subnets and ASes are becoming more ubiquitous in IPv4.&lt;/p&gt;

&lt;p&gt;3) Malicious ASes are likely large and deeply fragmented&lt;/p&gt;

&lt;p&gt;Further work is required to characterize the exact cost structure of buying subnets, registering IP blocks, and setting up infrastructure in malicious ASes.&lt;/p&gt;

&lt;p&gt;We’d also like to understand the network and system features that convince attackers to co-opt a specific AS over another. For example, we used Sonar’s historical forward­DNS service and our phishing detection algorithms to characterize the domains that have mapped to these ASes in the past two years. Domains hosted in malicious ASes had features that suggested deliberate use of specific infrastructure. For example, ‘wordpress’ sites were over-represented in some malicious ASes (like &lt;a href=&quot;https://www.google.com/transparencyreport/safebrowsing/malware/?hl=en#region=ALL&amp;amp;period=90&amp;amp;size=LARGEST&amp;amp;compromised&amp;amp;attack&amp;amp;asn=4808&amp;amp;page=1&quot;&gt;AS4808&lt;/a&gt;), and GoDaddy was by far the most popular registrar for malicious sites across the board. Are these features core to the design and sustenance of phishing attacks?&lt;/p&gt;

&lt;p&gt;As seen below, it’s also possible to analyze SSL certificates to uncover the distribution of devices hosted in ASes across IPv4.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig4.png&quot; alt=&quot;malicious infrastructure&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each square above shows the probability distribution of device counts of a particular type. Most ASes host fewer than 100 devices across a majority of categories. Are there skews in the types of devices used to propagate phishing attacks from these malicious ASes?&lt;/p&gt;

&lt;p&gt;This research represents an example of how Internet-scale data science can provide valuable insight on the threat landscape. We hope similar macro level research is inspired by these explorations.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks to Bob Rudis (&lt;a href=&quot;http://twitter.com/hrbrmstr&quot;&gt;@hrbrmstr&lt;/a&gt;) for help with this post.&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://sonar.labs.rapid7.com/&quot;&gt;Sonar intro&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://community.rapid7.com/community/infosec/blog/2016/01/05/12-days-of-haxmas-beginner-threat-intelligence-with-honeypots&quot;&gt;Heisenberg intro&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://eprints.eemcs.utwente.nl/20379/01/cnsm2011.pdf&quot;&gt;Internet Bad Neighborhoods: The spam case&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.cs.ucsb.edu/~chris/research/doc/acsac09_fire.pdf&quot;&gt;FIRE: FInding Rogue nEtworks&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=5783493&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F90%2F6151256%2F05783493.pdf%3Farnumber%3D5783493&quot;&gt;Abnormally Malicious Autonomous Systems and Their Internet Connectivity&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=5462220&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5462220&quot;&gt;Malicious Hubs: Detecting Abnormally Malicious Autonomous Systems&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://cleanmx.org&quot;&gt;Cleanmx archive&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.arin.net/fees/fee_schedule.html&quot;&gt;ARIN fee schedules&lt;/a&gt; &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:8:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Applying Machine Learning to Security Problems</title>
   <link href="https://suchin.co/2016/03/01/applying-machine-learning-to-security-problems/"/>
   <updated>2016-03-01T00:00:00-08:00</updated>
   <id>https://suchin.co/2016/03/01/applying-machine-learning-to-security-problems</id>
   <content type="html">&lt;p&gt;Anomaly detection is a hard process ridden with false alarms. The security community has been increasingly interested in the potential for data-driven tools to filter out noise and automatically detect malicious activity in large networks. However, while capable of overcoming the limitations of static, rule-based techniques, machine learning is not a silver bullet solution to detecting and responding to attacks.&lt;/p&gt;

&lt;p&gt;Adaptable models require a continuous flow of labeled data to train with. Unfortunately, the creation of such labeled data is the most expensive and time-consuming part of the data science process. Data is usually messy, incomplete, and inconsistent. While there are many tools to experiment with different algorithms and their parameters, there are few tools to help one develop clean, comprehensive datasets. Often times this means asking practitioners with deep domain expertise to help label existing datasets. But ground truth be hard to come by in the security context, and may go stale very quickly.&lt;/p&gt;

&lt;p&gt;On top of that, bias in training data can hamper the effectiveness of a model to discern between output classes. In the security context, data bias can be interpreted in two ways.&lt;/p&gt;

&lt;p&gt;First, attack methodologies are becoming more dynamic than ever before. If a predictive model is trained on known patterns and vulnerabilities (e.g. using features from malware that is file-system resident), it may not necessarily detect an unprecedented attack that does not conform to those trends (e.g. misses features from malware that is only memory resident).&lt;/p&gt;

&lt;p&gt;Second, data bias also comes in the form of &lt;em&gt;class representation&lt;/em&gt;&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. To understand class representation bias, one can look to a core foundation of statistics: Bayes theorem.&lt;/p&gt;

&lt;p&gt;Bayes theorem describes the probability of event A given event B:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(A | B) = \frac { P (A) P(B | A)}{P(B)}&lt;/script&gt;

&lt;p&gt;Expanding the probability P (B) for the set of two mutually exclusive outcomes, we arrive at the following equation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (B) = (A_1 )P (B|A_1 ) + (\neg A_2 )P (B|\neg A_2 )&lt;/script&gt;

&lt;p&gt;Combining the above equations, we arrive at the following alternative statement of Bayes’ theorem:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (A|B) = \frac{P (A)P (B|A)} {P (A_1 )P (B|A_1 ) + P (\neg A_2 )P (B|\neg A_2 )}&lt;/script&gt;

&lt;p&gt;Let’s apply this theorem to a concrete security problem to show the emergent issues of training predictive models on biased data.&lt;/p&gt;

&lt;p&gt;Suppose company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; has &lt;script type=&quot;math/tex&quot;&gt;1000&lt;/script&gt; employees, and a security vendor has deployed an intrusion detection system (IDS) alerting the company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; when it detects a malicious URL sent to an employee’s inbox. Suppose there are &lt;script type=&quot;math/tex&quot;&gt;10&lt;/script&gt; malicious URLs sent to employees of company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; per day. Finally, suppose the IDS analyzes &lt;script type=&quot;math/tex&quot;&gt;10000&lt;/script&gt; incoming URLs to company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; per day.&lt;/p&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;I&lt;/script&gt; denote an incident (an incoming malicious URL) and &lt;script type=&quot;math/tex&quot;&gt;\neg I&lt;/script&gt; denote a non-incident (an incoming benign URL).
Similarly, let &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; denote an alarm (the IDS classifies incoming URL as malicious) and &lt;script type=&quot;math/tex&quot;&gt;\neg A&lt;/script&gt; denote a non-alarm (the
IDS classifies URL as benign). That means &lt;script type=&quot;math/tex&quot;&gt;P (A|I) = P (\text{hit})&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P (A| \neg I) =
P (\text{false alarm})&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;What’s the probability that an alarm is associated with a real incident? In other words, &lt;em&gt;how much can we trust the IDS under these conditions?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Using Bayes’ Theorem from above, we know:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (I|A) = \frac{P (I)P (A|I)}{P (I)P (A|I) + P (\neg I)P (A|\neg I)}&lt;/script&gt;

&lt;p&gt;Put another way,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (\text{IDS is accurate}) = \frac{P (\text{incident})P (\text{hit})}{P (\text{incident})P (\text{hit}) + P (\text{non-incident})P (\text{false alarm})}&lt;/script&gt;

&lt;p&gt;Now let’s calculate &lt;script type=&quot;math/tex&quot;&gt;P(\text{incident})&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P(\text{non-incident})&lt;/script&gt;, given the parameters of the IDS problem we defined above:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\text{incident}) =\frac{\text{10 incidents per day}}{\text{10000 audits per day}} = 0.001&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (\text{non-incident}) = 1 − P (\text{incident}) = 0.999&lt;/script&gt;

&lt;p&gt;These probabilities emphasize the bias present in the distribution of analyzed URLs. The IDS has little sense of what incidents entail, as it is trained on very few examples of it. Plugging the probabilities into the equation above, we find that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (\text{IDS is accurate}) = \frac{0.001 * P (\text{hit})}{0.001 * P (\text{hit}) + 0.999 * P (\text{false alarm})}&lt;/script&gt;

&lt;p&gt;Thus, to have reasonable confidence in an IDS under these biased conditions, we must have not only unrealistically high hit rate, but also unrealistically low false positive rate. For example, for an IDS to be &lt;script type=&quot;math/tex&quot;&gt;80&lt;/script&gt; percent accurate, even with a best case scenario of a 100 percent hit rate, the IDS’ false alarm rate must be &lt;script type=&quot;math/tex&quot;&gt;4 \times 10^{−4}&lt;/script&gt; . In other words, only &lt;script type=&quot;math/tex&quot;&gt;4&lt;/script&gt; out of &lt;script type=&quot;math/tex&quot;&gt;10000&lt;/script&gt; alarms can be false
positives to achieve this accuracy.&lt;/p&gt;

&lt;p&gt;In the real world, detection hit rates are much lower and false alarm rates are much higher. Thus, class representation bias in the security context can make machine learning algorithms inaccurate and untrustworthy. When models are trained on only a few examples of one class but many examples of another, the bar for reasonable accuracy is extremely high, and in some cases unachievable. Predictive algorithms run the risk of being ”the boy who cried wolf” – annoying and prone to desensitizing security professionals to incident alerts.&lt;/p&gt;

&lt;p&gt;Security data scientists can avoid these obstacles with a few measures:&lt;/p&gt;

&lt;p&gt;1) &lt;strong&gt;Apply structure to data with supervised and semi-supervised learning.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2) &lt;strong&gt;Undersample the majority class and/or oversample the minority class.&lt;/strong&gt; See scikit learn’s stratified data splitting functions &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; and this repo &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;3) &lt;strong&gt;Generate synthetic data from minority class via algorithms like SMOTE.&lt;/strong&gt; See this repo&lt;sup id=&quot;fnref:3:1&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; again.&lt;/p&gt;

&lt;p&gt;5) &lt;strong&gt;Build models that penalize classification to the majority class.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;6) &lt;strong&gt;Focus on organization, presentation, visualization, filtering of data - not just prediction.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;7) &lt;strong&gt;Encourage data gathering expeditions.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;8) &lt;strong&gt;Encourage security expertise on the team.&lt;/strong&gt; Security expertise can help you think of viable solutions to problems when data is insufficient.&lt;/p&gt;

&lt;p&gt;9) &lt;strong&gt;Weigh the trade-off between accuracy vs. coverage.&lt;/strong&gt; The effects of false positives are particularly detrimental in the security space, meaning that for some applications it may be more useful to sacrifice the volume of accurate classifications for higher confidence.&lt;/p&gt;

&lt;p&gt;Machine learning has the potential to change how we detect and respond to malicious activity in our networks by weeding out signal from noise. It can help security professionals discover patterns in network activity never seen before. However, when applying these algorithms to security we have to be aware of caveats of the approach so we can address them.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://divac.ist.temple.edu/~vucetic/documents/vucetic01ecml.pdf&quot;&gt;Classification on Biased Data&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html#sklearn.cross_validation.StratifiedKFold&quot;&gt;Sklearn’s Stratified K-Fold&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://github.com/fmfn/UnbalancedDataset&quot;&gt;Handling Imbalanced Data&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:3:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Hello, World!</title>
   <link href="https://suchin.co/2016/02/12/hello-world/"/>
   <updated>2016-02-12T00:00:00-08:00</updated>
   <id>https://suchin.co/2016/02/12/hello-world</id>
   <content type="html">&lt;p&gt;Just testing out my blog.&lt;/p&gt;
</content>
 </entry>
 

</feed>
