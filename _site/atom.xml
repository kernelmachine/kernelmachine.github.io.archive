<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>suchin</title>
 <link href="http://suchin.co/atom.xml" rel="self"/>
 <link href="http://suchin.co/"/>
 <updated>2016-03-25T16:28:34-04:00</updated>
 <id>http://suchin.co</id>
 <author>
   <name>Suchin Gururangan</name>
   <email></email>
 </author>

 
 <entry>
   <title>The Topology of Malicious Activity on IPv4</title>
   <link href="http://suchin.co/2016/03/23/Topology-Of-Malicious-Activity/"/>
   <updated>2016-03-23T00:00:00-04:00</updated>
   <id>http://suchin.co/2016/03/23/Topology-Of-Malicious-Activity</id>
   <content type="html">&lt;p&gt;At Rapid7, we’re building tools that help us investigate the threat landscape across the Internet. Projects Sonar&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and Heisenberg&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; give us global exposure to common vulnerabilities and patterns in offensive attacks. Our machine learning projects can detect and characterize phishing URLs and SSL certificates. Our threat intelligence repository is growing with datasets that resolve malicious activity to address blocks and autonomous systems.&lt;/p&gt;

&lt;p&gt;We have recently focused our research on how these tools can work together to provide unique insights on the state of the Internet. In this post, we’ll present the beginning of our explorations to identify stable, macro-level attacks trends invisible on the scale of IP addresses.&lt;/p&gt;

&lt;h3 id=&quot;ipv4-topology&quot;&gt;IPv4 Topology&lt;/h3&gt;
&lt;p&gt;First, a quick primer on IPv4, the fourth version of the Internet Protocol. The topology of IPv4 is characterized by three levels of hierarchy, from smallest to largest: IP addresses, subnets, and autonomous systems (ASes). IP addresses on IPv4 are 32-bit sequences that identify hosts or network interfaces. Subnets are groups of IP addresses, and ASes are blocks of subnets managed by public institutions and private enterprises. IPv4 is divided into about 65,000 ASes, at least 30M subnets, and &lt;script type=&quot;math/tex&quot;&gt;2^{32}&lt;/script&gt; IP addresses.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig1.png&quot; alt=&quot;Phishing Activity&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;malicious-ases&quot;&gt;Malicious ASes&lt;/h3&gt;
&lt;p&gt;There has been a great deal of academic and industry focus on identifying malicious activity across
autonomous systems, and for good reasons.&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; Over 50% of “good” Internet traffic comes
from large, ocean-like ASes pushing content from companies like Netflix, Google, Facebook, Apple and Amazon.  However, despite this centralized content, the vastness of the Internet enables those with malicious intent to stake their claim in less friendly waters. In fact, our longitudinal data on phishing activity across IPv4 presented an interesting trend: &lt;em&gt;a small subset of autonomous systems have regularly hosted a disproportionate
amount of malicious activity&lt;/em&gt;. In particular, 200 ASes hosted 70% of phishing activity from 2007 to 2015
(data: cleanmx archives&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;). We wanted to understand what makes some autonomous systems more
likely to host malicious activity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig2.png&quot; alt=&quot;IPv4 fragmentation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ipv4-fragmentation&quot;&gt;IPv4 Fragmentation&lt;/h3&gt;

&lt;p&gt;We gathered historical mappings between IP addresses and ASes from 2007 to 2015 to understand the history of IPv4. The data clearly suggested that IPv4 has been fragmenting. The total number of ASes has grown about 60% in the past decade, and during the same period, there has been a rise in the number of small ASes and a decline in the number of large ones. These results make sense given that the IPV4 address space has been exhausted. This means that growth in IPv4 access requires the reallocation of existing address space into smaller and smaller independent blocks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig3.png&quot; alt=&quot;AS fragmentation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;as-fragmentation&quot;&gt;AS Fragmentation&lt;/h3&gt;

&lt;p&gt;Digging deeper into the Internet’s topological hierarchy, we analyzed the composition, size, and fragmentation of malicious ASes.&lt;/p&gt;

&lt;p&gt;ARIN, one of the primary registrars of ASes, categorizes subnets based on the number of IP addresses they contain.&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; We found that the smallest subnets available made up on average 56 &lt;script type=&quot;math/tex&quot;&gt;\pm&lt;/script&gt; 3.0 percent of a malicious AS.&lt;/p&gt;

&lt;p&gt;Furthermore, we inferred the the size of an AS by calculating its maximum amount of addressable space. Malicious ASes were in the 80-90th percentile in size across IPv4.&lt;/p&gt;

&lt;p&gt;Finally, to compute fragmentation, subnets observed in ASes overtime were organized into trees based on parent-child relationships (Figure 3). We then calculated the ratio of the number of root subnets, which have no parents, to the number of child subnets across the lifetime of the AS. We found that malicious ASes were 10-20% more fragmented than other ASes in IPv4.&lt;/p&gt;

&lt;p&gt;These results suggest that malicious ASes are large and deeply fragmented into small subnets. ARIN fee schedules showed that smaller subnets are significantly less expensive to purchase.&lt;sup id=&quot;fnref:8:1&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; Cheap, small subnets may allow malicious registrars to purchase many IP blocks for traffic redirection or proxy servers, so they can better float under the radar.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig5.png&quot; alt=&quot;topologies&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Our research presents the following results:&lt;/p&gt;

&lt;p&gt;1) A small subset of ASes host a disproportionate amount of malicious activity.&lt;/p&gt;

&lt;p&gt;2) Smaller subnets and ASes are becoming more ubiquitous in IPv4.&lt;/p&gt;

&lt;p&gt;3) Malicious ASes are likely large and deeply fragmented&lt;/p&gt;

&lt;p&gt;Further work is required to characterize the exact cost structure of buying subnets, registering IP blocks, and setting up infrastructure in malicious ASes.&lt;/p&gt;

&lt;p&gt;We’d also like to understand the network and system features that convince attackers to co-opt a specific AS over another. For example, we used Sonar’s historical forward­DNS service and our phishing detection algorithms to characterize the domains that have mapped to these ASes in the past two years. Domains hosted in malicious ASes had features that suggested deliberate use of specific infrastructure. For example, ‘wordpress’ sites were over-represented in some malicious ASes (like &lt;a href=&quot;https://www.google.com/transparencyreport/safebrowsing/malware/?hl=en#region=ALL&amp;amp;period=90&amp;amp;size=LARGEST&amp;amp;compromised&amp;amp;attack&amp;amp;asn=4808&amp;amp;page=1&quot;&gt;AS4808&lt;/a&gt;), and GoDaddy was by far the most popular registrar for malicious sites across the board. Are these features core to the design and sustenance of phishing attacks?&lt;/p&gt;

&lt;p&gt;As seen below, it’s also possible to analyze SSL certificates to uncover the distribution of devices hosted in ASes across IPv4.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pegasos1.github.io/public/20160215/fig4.png&quot; alt=&quot;malicious infrastructure&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each square above shows the probability distribution of device counts of a particular type. Most ASes host fewer than 100 devices across a majority of categories. Are there skews in the types of devices used to propagate phishing attacks from these malicious ASes?&lt;/p&gt;

&lt;p&gt;This research represents an example of how Internet-scale data science can provide valuable insight on the threat landscape. We hope similar macro level research is inspired by these explorations.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks to Bob Rudis (&lt;a href=&quot;http://twitter.com/hrbrmstr&quot;&gt;@hrbrmstr&lt;/a&gt;) for help with this post.&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://sonar.labs.rapid7.com/&quot;&gt;Sonar intro&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://community.rapid7.com/community/infosec/blog/2016/01/05/12-days-of-haxmas-beginner-threat-intelligence-with-honeypots&quot;&gt;Heisenberg intro&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://eprints.eemcs.utwente.nl/20379/01/cnsm2011.pdf&quot;&gt;Internet Bad Neighborhoods: The spam case&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.cs.ucsb.edu/~chris/research/doc/acsac09_fire.pdf&quot;&gt;FIRE: FInding Rogue nEtworks&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=5783493&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F90%2F6151256%2F05783493.pdf%3Farnumber%3D5783493&quot;&gt;Abnormally Malicious Autonomous Systems and Their Internet Connectivity&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=5462220&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5462220&quot;&gt;Malicious Hubs: Detecting Abnormally Malicious Autonomous Systems&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://cleanmx.org&quot;&gt;Cleanmx archive&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.arin.net/fees/fee_schedule.html&quot;&gt;ARIN fee schedules&lt;/a&gt; &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:8:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Applying Machine Learning to Security Problems</title>
   <link href="http://suchin.co/2016/03/01/applying-machine-learning-to-security-problems/"/>
   <updated>2016-03-01T00:00:00-05:00</updated>
   <id>http://suchin.co/2016/03/01/applying-machine-learning-to-security-problems</id>
   <content type="html">&lt;p&gt;Anomaly detection is a hard process ridden with false alarms. The security community
has been increasingly interested in the potential for data-driven tools to filter out
noise and automatically detect malicious activity in large networks. However, while capable
of overcoming the limitations of static, rule-based techniques, machine learning
is not a silver bullet solution to detecting and responding to attacks.&lt;/p&gt;

&lt;p&gt;Adaptable models require a continuous flow of labeled data to train with. Unfortunately, the creation of such labeled data is the most
expensive and time-consuming part of the data science process. Data is usually messy, incomplete, and inconsistent.
While there are many tools to experiment with different algorithms and
their parameters, there are few tools to help one develop clean, comprehensive
datasets. Often times this means asking practitioners with deep domain expertise
to help label existing datasets. But ground truth be hard to come by
in the security context, and may go stale very quickly.&lt;/p&gt;

&lt;p&gt;On top of that, bias in training data can hamper the effectiveness of a model
to discern between output classes. In the security context, data bias can be
interpreted in two ways.&lt;/p&gt;

&lt;p&gt;First, attack methodologies are becoming more dynamic than ever before. If a predictive model is trained on
known patterns and vulnerabilities (e.g. using features from malware that is file-system resident),
it may not necessarily detect an unprecedented attack that does not conform
 to those trends (e.g. misses features from malware that is only memory resident).&lt;/p&gt;

&lt;p&gt;Second, data bias also comes in the form of &lt;em&gt;class representation&lt;/em&gt;&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. To understand
class representation bias, one can look to a core foundation of statistics: Bayes
theorem.&lt;/p&gt;

&lt;p&gt;Bayes theorem describes the probability of event A given event B:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(A | B) = \frac { P (A) P(B | A)}{P(B)}&lt;/script&gt;

&lt;p&gt;Expanding the probability P (B) for the set of two mutually exclusive outcomes,
we arrive at the following equation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (B) = (A_1 )P (B|A_1 ) + (\neg A_2 )P (B|\neg A_2 )&lt;/script&gt;

&lt;p&gt;Combining the above equations, we arrive at the following alternative statement
of Bayes’ theorem:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (A|B) = \frac{P (A)P (B|A)} {P (A_1 )P (B|A_1 ) + P (\neg A_2 )P (B|\neg A_2 )}&lt;/script&gt;

&lt;p&gt;Let’s apply this theorem to a concrete security problem to show the emergent
issues of training predictive models on biased data.&lt;/p&gt;

&lt;p&gt;Suppose company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; has &lt;script type=&quot;math/tex&quot;&gt;1000&lt;/script&gt; employees, and a security vendor has deployed an
intrusion detection system (IDS) alerting the company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; when it detects a malicious
URL sent to an employee’s inbox. Suppose there are &lt;script type=&quot;math/tex&quot;&gt;10&lt;/script&gt; malicious URLs
sent to employees of company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; per day. Finally, suppose the IDS analyzes
&lt;script type=&quot;math/tex&quot;&gt;10000&lt;/script&gt; incoming URLs to company &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; per day.&lt;/p&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;I&lt;/script&gt; denote an incident (an incoming malicious URL) and &lt;script type=&quot;math/tex&quot;&gt;\neg I&lt;/script&gt; denote a non-incident (an incoming benign URL).
Similarly, let &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; denote an alarm (the IDS classifies incoming URL as malicious) and &lt;script type=&quot;math/tex&quot;&gt;\neg A&lt;/script&gt; denote a non-alarm (the
IDS classifies URL as benign). That means &lt;script type=&quot;math/tex&quot;&gt;P (A|I) = P (\text{hit})&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P (A| \neg I) =
P (\text{false alarm})&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;What’s the probability that an alarm is associated with a real incident? In other
words, &lt;em&gt;how much can we trust the IDS under these conditions?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Using Bayes’ Theorem from above, we know:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (I|A) = \frac{P (I)P (A|I)}{P (I)P (A|I) + P (\neg I)P (A|\neg I)}&lt;/script&gt;

&lt;p&gt;Put another way,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (\text{IDS is accurate}) = \frac{P (\text{incident})P (\text{hit})}{P (\text{incident})P (\text{hit}) + P (\text{non-incident})P (\text{false alarm})}&lt;/script&gt;

&lt;p&gt;Now let’s calculate &lt;script type=&quot;math/tex&quot;&gt;P(\text{incident})&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P(\text{non-incident})&lt;/script&gt;, given the parameters of
the IDS problem we defined above:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\text{incident}) =\frac{\text{10 incidents per day}}{\text{10000 audits per day}} = 0.001&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (\text{non-incident}) = 1 − P (\text{incident}) = 0.999&lt;/script&gt;

&lt;p&gt;These probabilities emphasize the bias present in the distribution of analyzed
URLs. The IDS has little sense of what incidents entail, as it is trained on very
few examples of it. Plugging the probabilities into the equation above, we find
that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P (\text{IDS is accurate}) = \frac{0.001 * P (\text{hit})}{0.001 * P (\text{hit}) + 0.999 * P (\text{false alarm})}&lt;/script&gt;

&lt;p&gt;Thus, to have reasonable confidence in an IDS under these biased conditions,
we must have not only unrealistically high hit rate, but also unrealistically low
false positive rate. For example, for an IDS to be &lt;script type=&quot;math/tex&quot;&gt;80&lt;/script&gt; percent accurate, even with
a best case scenario of a 100 percent hit rate, the IDS’ false alarm rate must be
&lt;script type=&quot;math/tex&quot;&gt;4 \times 10^{−4}&lt;/script&gt; . In other words, only &lt;script type=&quot;math/tex&quot;&gt;4&lt;/script&gt; out of &lt;script type=&quot;math/tex&quot;&gt;10000&lt;/script&gt; alarms can be false
positives to achieve this accuracy.&lt;/p&gt;

&lt;p&gt;In the real world, detection hit rates are much lower and false alarm rates are
much higher. Thus, class representation bias in the security context can make
machine learning algorithms inaccurate and untrustworthy. When models are
trained on only a few examples of one class but many examples of another, the
bar for reasonable accuracy is extremely high, and in some cases unachievable.
Predictive algorithms run the risk of being ”the boy who cried wolf” – annoying
and prone to desensitizing security professionals to incident alerts.&lt;/p&gt;

&lt;p&gt;Security data scientists can avoid these obstacles with a few measures:&lt;/p&gt;

&lt;p&gt;1) &lt;strong&gt;Apply structure to data with supervised and semi-supervised learning.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2) &lt;strong&gt;Undersample the majority class and/or oversample the minority class.&lt;/strong&gt; See scikit learn’s stratified data splitting functions &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; and this repo &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;3) &lt;strong&gt;Generate synthetic data from minority class via algorithms like SMOTE.&lt;/strong&gt; See this repo&lt;sup id=&quot;fnref:3:1&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; again.&lt;/p&gt;

&lt;p&gt;5) &lt;strong&gt;Build models that penalize classification to the majority class.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;6) &lt;strong&gt;Focus on organization, presentation, visualization, filtering of data - not just prediction.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;7) &lt;strong&gt;Encourage data gathering expeditions.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;8) &lt;strong&gt;Encourage security expertise on the team.&lt;/strong&gt; Security expertise can help you think of viable solutions to problems when
data is insufficient.&lt;/p&gt;

&lt;p&gt;9) &lt;strong&gt;Weigh the trade-off between accuracy vs. coverage.&lt;/strong&gt; The effects of false positives are particularly
detrimental in the security space, meaning that for some applications it may be more useful to sacrifice
the volume of accurate classifications for higher confidence.&lt;/p&gt;

&lt;p&gt;Machine learning has the potential to change how we detect and respond to malicious activity in our networks by weeding out signal from noise. It can help
security professionals discover patterns in network activity never seen before. However, when applying these
algorithms to security we have to be aware of caveats of the approach so we can address them.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://divac.ist.temple.edu/~vucetic/documents/vucetic01ecml.pdf&quot;&gt;Classification on Biased Data&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html#sklearn.cross_validation.StratifiedKFold&quot;&gt;Sklearn’s Stratified K-Fold&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://github.com/fmfn/UnbalancedDataset&quot;&gt;Handling Imbalanced Data&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:3:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Hello, World!</title>
   <link href="http://suchin.co/2016/02/12/hello-world/"/>
   <updated>2016-02-12T00:00:00-05:00</updated>
   <id>http://suchin.co/2016/02/12/hello-world</id>
   <content type="html">&lt;p&gt;I’m Suchin. I’m a data scientist at Rapid7, a security company in Cambridge, MA.&lt;/p&gt;

&lt;p&gt;This blog will condense and communicate things I’m working on and reading about. It’s a way for me to understand
material and practice writing, and for readers to learn something new.&lt;/p&gt;

&lt;p&gt;Topics will be all over the place: machine learning to security, programming to books.&lt;/p&gt;

&lt;p&gt;Thanks for reading!&lt;/p&gt;
</content>
 </entry>
 

</feed>
